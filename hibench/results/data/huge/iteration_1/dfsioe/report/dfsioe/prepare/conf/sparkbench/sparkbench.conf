# Source: /root/HiBench/conf/hadoop.conf
hibench.hadoop.configure.dir	/usr/hdp/current/hadoop-client/conf
hibench.hadoop.examples.jar	/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar
hibench.hadoop.examples.test.jar	/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar
hibench.hadoop.executable	/usr/hdp/current/hadoop-client/bin/hadoop
hibench.hadoop.home	/usr/hdp/current/hadoop-client
hibench.hadoop.release	hdp
hibench.hdfs.master	wasbs://simexpcontainer@simexpstoro4rjzqiy.blob.core.windows.net

# Source: /root/HiBench/conf/hibench.conf
hibench.bayes.dir.name.input	Input
hibench.bayes.dir.name.output	Output
hibench.common.jar	/root/HiBench/common/target/hibench-common-8.0-SNAPSHOT-jar-with-dependencies.jar
hibench.configure.dir	/root/HiBench/conf
hibench.default.map.parallelism	10
hibench.default.shuffle.parallelism	10
hibench.dfsioe.dir.name.input	Input
hibench.dfsioe.dir.name.output	Output
hibench.hdfs.data.dir	wasbs://simexpcontainer@simexpstoro4rjzqiy.blob.core.windows.net/HiBench
hibench.hibench.datatool.dir	/root/HiBench/autogen/target/autogen-8.0-SNAPSHOT-jar-with-dependencies.jar
hibench.hive.home	/root/HiBench/hadoopbench/sql/target/apache-hive-3.0.0-bin
hibench.hive.release	apache-hive-3.0.0-bin
hibench.hivebench.template.dir	/root/HiBench/hadoopbench/sql/hive_template
hibench.mahout.home	/root/HiBench/hadoopbench/mahout/target/
hibench.mahout.release	
hibench.mahout.release.apache	apache-mahout-distribution-0.11.0
hibench.nutch.dir.name.input	Input
hibench.nutch.dir.name.output	Output
hibench.nutch.home	/root/HiBench/hadoopbench/nutchindexing/target/nutch-1.2
hibench.nutch.nutchindexing.dir	/root/HiBench/hadoopbench/nutchindexing/
hibench.nutch.release	nutch-1.2
hibench.report.dir	/root/HiBench/report
hibench.report.formats	"%-12s %-10s %-8s %-20s %-20s %-20s %-20s\n"
hibench.report.name	hibench.report
hibench.scale.profile	huge
hibench.sparkbench.jar	/root/HiBench/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
hibench.streambench.datagen.data1.dir	wasbs://simexpcontainer@simexpstoro4rjzqiy.blob.core.windows.net/HiBench/Streaming/Seed
hibench.streambench.datagen.data1.name	Seed
hibench.streambench.datagen.data2_cluster.dir	wasbs://simexpcontainer@simexpstoro4rjzqiy.blob.core.windows.net/HiBench/Streaming/Kmeans/Cluster
hibench.streambench.datagen.data2_samples.dir	wasbs://simexpcontainer@simexpstoro4rjzqiy.blob.core.windows.net/HiBench/Streaming/Kmeans/Samples
hibench.streambench.datagen.dir	wasbs://simexpcontainer@simexpstoro4rjzqiy.blob.core.windows.net/HiBench/Streaming
hibench.streambench.datagen.intervalSpan	50
hibench.streambench.datagen.producerNumber	1
hibench.streambench.datagen.recordLength	200
hibench.streambench.datagen.recordsPerInterval	5
hibench.streambench.datagen.totalRecords	-1
hibench.streambench.datagen.totalRounds	-1
hibench.streambench.debugMode	false
hibench.streambench.fixWindowDuration	10000
hibench.streambench.fixWindowSlideStep	10000
hibench.streambench.flinkbench.jar	/root/HiBench/flinkbench/streaming/target/flinkbench-streaming-8.0-SNAPSHOT-jar-with-dependencies.jar
hibench.streambench.gearpump.jar	/root/HiBench/gearpumpbench/streaming/target/gearpumpbench-streaming-8.0-SNAPSHOT-jar-with-dependencies.jar
hibench.streambench.kafka.brokerList	
hibench.streambench.kafka.consumerGroup	HiBench
hibench.streambench.kafka.home	/PATH/TO/YOUR/KAFKA/HOME
hibench.streambench.kafka.offsetReset	largest
hibench.streambench.kafka.topicPartitions	20
hibench.streambench.metricsReader.outputDir	/root/HiBench/report
hibench.streambench.metricsReader.sampleNum	5000000
hibench.streambench.metricsReader.threadNum	20
hibench.streambench.sampleProbability	0.1
hibench.streambench.stormbench.jar	/root/HiBench/stormbench/streaming/target/stormbench-streaming-8.0-SNAPSHOT.jar
hibench.streambench.zkHost	
hibench.workload.dir.name.input	Input
hibench.workload.dir.name.output	Output
sparkbench.inputformat	Sequence
sparkbench.outputformat	Sequence

# Source: /root/HiBench/conf/spark.conf
hibench.spark.home	/usr/hdp/current/spark2-client
hibench.spark.master	local[*]
hibench.spark.version	spark2.4
hibench.yarn.executor.cores	4
hibench.yarn.executor.num	2

# Source: /root/HiBench/conf/workloads/micro/dfsioe.conf
hibench.dfsioe.huge.read.file_size	100
hibench.dfsioe.huge.read.number_of_files	256
hibench.dfsioe.huge.write.file_size	100
hibench.dfsioe.huge.write.number_of_files	256
hibench.dfsioe.large.read.file_size	10
hibench.dfsioe.large.read.number_of_files	64
hibench.dfsioe.large.write.file_size	10
hibench.dfsioe.large.write.number_of_files	64
hibench.dfsioe.read.file_size	100
hibench.dfsioe.read.number_of_files	256
hibench.dfsioe.read_only	false
hibench.dfsioe.small.read.file_size	10
hibench.dfsioe.small.read.number_of_files	32
hibench.dfsioe.small.write.file_size	10
hibench.dfsioe.small.write.number_of_files	32
hibench.dfsioe.write.file_size	100
hibench.dfsioe.write.number_of_files	256
hibench.workload.input	wasbs://simexpcontainer@simexpstoro4rjzqiy.blob.core.windows.net/HiBench/Dfsioe/Input
hibench.workload.output	wasbs://simexpcontainer@simexpstoro4rjzqiy.blob.core.windows.net/HiBench/Dfsioe/Output

# Source: Inferred from relative path of dirname(/root/HiBench/bin/functions/load_config.py)/../../
hibench.home	/root/HiBench

# Source: Probed by configuration file:'/usr/hdp/current/hadoop-client/conf/mapred-site.xml'
hibench.dfsioe.map.java_opts	'-Xmx2560M -Xms2560M -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseParallelGC'
hibench.dfsioe.red.java_opts	'-Xmx2560M -Xms2560M -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseParallelGC'

# Source: Probed by the evidence of 'hibench.spark.master=local[*]'
hibench.masters.hostnames	''
hibench.slaves.hostnames	'localhost'

# Source: Refer to `hibench.hadoop.examples.test.jar` according to the evidence of `hibench.hadoop.release`
hibench.sleep.job.jar	/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar

# Source: Use default mapper name
hibench.hadoop.mapper.name	mapreduce.job.maps

# Source: Use default reducer name
hibench.hadoop.reducer.name	mapreduce.job.reduces

