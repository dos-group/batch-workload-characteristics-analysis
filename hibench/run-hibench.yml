- name: Run HiBench with CPU Monitoring
  hosts: head_node
  become: yes
  vars:
    hibench_home: "/root/HiBench"
    monitoring_interval: 5 # Interval in seconds between samples
    tmux_sar_session: "sar_monitoring"

  pre_tasks:
    - name: Set local result directory
      set_fact:
        local_results_dir: "results/{{ lookup('pipe', \"date +'%Y-%m-%d_%H-%M'\") }}"

  tasks:
    - name: Install prerequisites
      block:
        - name: Ensure sysstat is installed
          apt:
            name: sysstat
            state: present
          when: ansible_os_family == "Debian"

        - name: Ensure tmux is installed
          apt:
            name: tmux
            state: present
          when: ansible_os_family == "Debian"

    - name: Setup CPU Monitoring Nodes
      block:
        - name: Ensure /tmp/data directory exists
          file:
            path: /tmp/data
            state: directory
          delegate_to: "{{ item }}"
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

        - name: Delete old system activity file if it exists
          file:
            path: /tmp/system_activity.bin
            state: absent
          delegate_to: "{{ item }}"
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

    - name: Configure HiBench
      block:
        - name: Copy local configuration files to HiBench conf directory
          copy:
            src: "{{ item.src }}"
            dest: "{{ hibench_home }}/conf/{{ item.dest }}"
            owner: root
            group: root
            mode: "0644"
          loop:
            - { src: "./conf/spark.conf", dest: "spark.conf" }
            - { src: "./conf/hadoop.conf", dest: "hadoop.conf" }
            - { src: "./conf/hibench.conf", dest: "hibench.conf" }

        - name: Set hdfs_master in hadoop.conf
          block:
            - name: Read hdfs_master from core-site.xml
              shell: >
                grep '<name>fs.defaultFS</name>' /usr/hdp/current/hadoop-client/conf/core-site.xml -A1 | grep value | 
                awk -F '>' '{print $2}' | awk -F '<' '{print $1}'
              register: hdfs_master

            - name: Replace value in hadoop.conf
              lineinfile:
                path: "{{ hibench_home }}/conf/hadoop.conf"
                regexp: "^hibench.hdfs.master.*"
                line: "hibench.hdfs.master    {{ hdfs_master.stdout }}"

    - name: Run HiBench and monitor system activity
      block:
        - name: Start comprehensive system monitoring with sar
          shell: tmux new-session -d -s {{ tmux_sar_session }} 'sar -o /tmp/system_activity.bin {{ monitoring_interval }}'
          delegate_to: "{{ item }}"
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

        - name: Run wordcount benchmark
          command: >
            {{ hibench_home }}/bin/workloads/micro/sort/prepare/prepare.sh 
            {{ hibench_home }}/bin/workloads/micro/sort/hadoop/run.sh
          register: wordcount_result
          until: wordcount_result.rc == 0
          retries: 3
          delay: 10

        - name: Stop monitoring session
          shell: tmux kill-session -t {{ tmux_sar_session }}
          delegate_to: "{{ item }}"
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

    - name: Download hibench results from head node
      block:
        - name: Copy benchmark results to local directory
          synchronize:
            src: "{{ hibench_home }}/report"
            dest: "{{ local_results_dir }}"
            mode: pull

        - name: Remove system usage directory from each node
          file:
            path: "{{ hibench_home }}/report"
            state: absent

    - name: Download monitoring results from nodes
      block:
        - name: Ensure local directory exists for each node
          local_action:
            module: file
            path: "{{ local_results_dir }}/monitoring_data/{{ item }}"
            state: directory
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

        - name: Convert CPU usage report to CSV
          shell: sadf -d /tmp/system_activity.bin -- -u > /tmp/data/cpu_usage_report.csv
          delegate_to: "{{ item }}"
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

        - name: Convert memory usage report to CSV
          shell: sadf -d /tmp/system_activity.bin -- -r > /tmp/data/memory_usage_report.csv
          delegate_to: "{{ item }}"
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

        - name: Convert IO usage report to CSV
          shell: sadf -d /tmp/system_activity.bin -- -b > /tmp/data/io_usage_report.csv
          delegate_to: "{{ item }}"
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

        - name: Convert network usage report to CSV
          shell: sadf -d /tmp/system_activity.bin -- -n DEV > /tmp/data/network_usage_report.csv
          delegate_to: "{{ item }}"
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

        - name: Synchronize data from each node to localhost
          local_action:
            module: command
            cmd: scp {{ ansible_user }}@{{ ansible_host }}:/tmp/data/* {{ local_results_dir }}/monitoring_data/{{ item }}/
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"

        - name: Remove system usage directory from each node
          file:
            path: "/tmp/data"
            state: absent
          delegate_to: "{{ item }}"
          loop: "{{ groups['head_node'] + groups['worker_nodes'] }}"
