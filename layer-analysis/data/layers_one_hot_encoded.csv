Title,Year,BibTex id,Parameters,BigDataFrameworkLayer,DataLayer,HardwareLayer,PerformanceLayer,UserApplicationLayer,VirtualisationLayer
Performance Prediction for Apache Spark Platform,2015,wang_performance_2015,"(de)serialization time,Start and Cleanup Time,Number of Nodes,Number of CPU Cores per Node,Task I/O Read Cost,Task I/O Write Cost,Task Memory Requirement",0,0,1,1,0,0
Hadoop Performance Self-Tuning Using a Fuzzy-Prediction Approach,2016,lee_hadoop_2016,"Number of Slots,Number of CPU Cores,Memory Size",1,0,1,0,0,0
Comparison and Improvement of Hadoop MapReduce Performance Prediction Models in the Private Cloud,2016,shen_novel_2023,"Framework Parameter Configuration,Job parameters,Application Type,Data Input Size,Number of Nodes",1,1,1,0,1,0
BigExplorer: A configuration recommendation system for big data platform,2016,yeh_bigexplorer_2016,"Framework Parameter Configuration,Job History,System Logs,Workload Type,Historical Execution Time",1,0,0,1,1,0
Performance modeling for spark using SVM,2016,luo_performance_2016,Framework Parameter Configuration,1,0,0,0,0,0
Selecting resources for distributed dataflow systems according to runtime targets,2016,thamsen_selecting_2016,"Input Parameters,Data Input Size,Basic information on previously executed jobs,Number of CPU Cores,Memory Size",0,1,1,0,1,0
Continuously improving the resource utilization of iterative parallel dataflows,2016,thamsen_continuously_2016,"CPU Utilisation - CPU Time,Available Resources,Sensable Lower Bound Ressource Utilisation,JVM CPU Time,Workflow Structure (Spark DAG)",1,0,0,1,0,0
Support vector regression model for BigData systems,2016,rizzi_support_2016,"Workflow Structure (Spark DAG),Number of CPU Cores,Historical Execution Time,Data Input Size,number of bytes transferred during shuﬄes",1,1,1,1,0,0
Estimation Accuracy on Execution Time of Run-Time Tasks in a Heterogeneous Distributed Environment,2016,liu_estimation_2016,"Historical Execution Time,Running Tasks,Progress of running of Tasks,Task Timestamps",1,0,0,1,0,0
Ellis: dynamically scaling distributed dataflows to meet runtime targets,2017,thamsen_ellis_2017,"Number of Runs (Historical),Ressource Utilisation Data,Available Resources,Stage Execution Time",1,0,0,1,0,0
dSpark: Deadline-Based Resource Allocation for Big Data Applications in Apache Spark,2017,islam_dspark_2017,"Framework Parameter Configuration,Workload Type,Ressource Utilisation Data",1,0,0,0,1,0
BBQ: Elastic MapReduce over Cloud Platforms,2017,chalvantzis_bbq_2017,"Data Input Size,Number of Tasks,Number of Nodes,Number of Job Stages",1,1,1,0,0,0
Performance Tuning and Modeling for Big Data Applications in Docker Containers,2017,ye_performance_2017,"CPU Utilisation - Overall,Disk Read Speed,Disk Write Speed,Memory Size per Node,Docker Configuration,resource interference",0,0,1,1,0,1
iSpot: achieving predictable performance for big data analytics with cloud transient servers,2017,xu_ispot_2017,"Data (de)serialization time,Garbage collection time,Data Input Size,Workflow Structure (Spark DAG),Historical Execution Time,Disk bandwidth,Number of Nodes,Data processing ratio,data localization ratio,Data Processing Rate,Parallelism factor,Available Network Bandwidth",1,1,1,1,0,1
A collaborative filtering based approach to performance prediction for parallel applications,2017,shao_collaborative_2017,"Memory Size per Node,Slot Memory,CPU Cores per Slot,Number of Slots,number of partitions,Completed Stages,Data Input Size,Number of CPU Cores",1,1,1,0,0,0
Model-Based Performance Evaluation of Batch and Stream Applications for Big Data,2017,krob_model-based_2017,"Workflow Structure (Spark DAG),Data Chunks Size,Input Parameters,Number of Nodes",1,0,1,0,1,0
Fluid Petri Nets for the Performance Evaluation of MapReduce and Spark Applications,2017,gianniti_fluid_2017,"Workflow Structure (Spark DAG),Number of Tasks,Number of Slots",1,0,0,0,0,0
A Combined Analytical Modeling Machine Learning Approach for Performance Prediction of MapReduce Jobs in Cloud Environment,2017,ataie_combined_2016,"Historical Execution Time,Number of CPU Cores,Data Input Size,Running Tasks,Completed Tasks,Workflow Structure (Spark DAG)",1,1,1,1,0,0
CherryPick: Adaptively Unearthing the Best Cloud Configurations for Big Data Analytics,2017,alipourfard_cherrypick_nodate,"Number of Cloud Instances,Number of CPU Cores,CPU Processing Power,Number of Disks,Disk Read Speed,Disk Write Speed,Network bandwidth,RAM per Core,Price per Hour",0,0,1,0,0,1
On MapReduce Scheduling in Hadoop Yarn on Heterogeneous Clusters,2018,wang_mapreduce_2018,"Job queue,Task Memory Requirement,Task CPU Requirement,Node Manager CPU Idle,Node Manager Memory Idle,Node Manager CPU Time ,Node Manager Memory,Local Map Tasks Count of a Job,Job Priority User Specified,Job Data Size,Job Dynamic Priority",1,0,0,1,0,0
Sparks operation time predictive in cloud computing environment based on SRC-WSVR,2018,li_sparks_2018,"(de)serialization time,Task Execution Time,Start and Cleanup Time,Number of CPU Cores per Node,Number of Nodes,Data Input Size,Memory Size per Node",0,1,1,1,0,0
A gray-box performance model for Apache Spark,2018,chao_gray-box_2018,"Framework Parameter Configuration,Data Input Size",1,1,0,0,0,0
Datasize-aware high dimensional configurations auto-tuning of in-memory cluster computing,2018,yu_datasize-aware_2018,"Data Input Size,Framework Parameter Configuration",1,1,0,0,0,0
Auto-tuning spark configurations based on neural network,2018,gu_auto-tuning_2018,"Historical Execution Time,Framework Parameter Configuration",1,0,0,1,0,0
CoBell: Runtime Prediction for Distributed Dataflow Jobs in Shared Clusters,2018,verbitskiy_cobell_2018,"Input Parameters,Data Input Size,Basic information on previously executed jobs,Number of CPU Cores,Memory Size,Historical Execution Time",0,1,1,1,1,0
Performance Prediction of Cloud-Based Big Data Applications,2018,ardagna_performance_2018,"Workflow Structure (Spark DAG),Running Tasks,Completed Stages,Completed Tasks",1,0,0,0,0,0
Towards optimal resource provisioning for Hadoop-MapReduce jobs using scale-out strategy and its performance analysis in private cloud environment,2019,ramanathan_towards_2019,"Data Input Size,Number of Tasks,hardware speciﬁcations / machine name,Data Chunks Size,Framework Parameter Configuration",1,1,1,0,0,0
Cost-Effective Cloud Server Provisioning for Predictable Performance of Big Data Analytics,2019,xu_cost-effective_2019,"Data Input Size,Number of Job Stages,(de)serialization time,Garbage collection time,Number of Tasks,Price per Hour,Cloud Machine Type,Number of Cloud Instances",1,1,0,0,0,1
Analytical composite performance models for Big Data applications,2019,karimian-aliabadi_analytical_2019,Workflow Structure (Spark DAG),1,0,0,0,0,0
PerTract: Model Extraction and Specification of Big Data Systems for Performance Prediction by the Example of Apache Spark and Hadoop,2019,kros_pertract_2019,"JVM CPU Time,CPU Utilisation - CPU Time,CPU Utilisation - Providing Infrastructure ,Task I/O Read Cost,Network latency,CPU Utilisation - (de)serialization time,Available Network Bandwidth,Task I/O Write Cost",0,0,0,1,0,0
Mapreduce performance model for Hadoop 2.x,2019,glushkova_mapreduce_2019,"Number of Disk per Node,Number of Nodes,Framework Parameter Configuration,Number of Job Stages,Number of CPU Cores per Node,Task Execution Time,Processing Latency",1,0,1,1,0,0
Fast. Efficient Performance Predictions for Big Data Applications,2019,maroulis_fast_2019,"Historical Execution Time,Data Input Size,Number of CPU Cores,Memory Size",0,1,1,1,0,0
Scalable Performance Modeling and Evaluation of MapReduce Applications,2019,ataie_combined_2016,"Workflow Structure (Spark DAG),Running Tasks,Completed Tasks,Completed Stages",1,0,0,0,0,0
Fast and Lightweight Execution Time Predictions for Spark Applications,2019,amannejad_fast_2019,"CPU Cores per Slot,number of partitions,Historical Execution Time",1,0,0,1,0,0
Quick Execution Time Predictions for Spark Applications,2019,amannejad_fast_2019,"CPU Cores per Slot,number of partitions,Historical Execution Time,Data Input Size",1,1,0,1,0,0
Machine learning for performance prediction of spark cloud applications,2019,maros_machine_2019,"Data processing ratio,Number of CPU Cores,Data Input Size,Number of Tasks,Historical Execution Time",1,1,1,1,0,0
Estimating runtime of a job in Hadoop MapReduce,2020,peyravi_estimating_2020,"Data Input Size,Framework Parameter Configuration,Number of Nodes,Number of Slots,CPU Processing Power,Number of CPU Cores per Node,RAM Write Speed,RAM Read Speed,Disk Write Speed,Disk Read Speed,Available Network Bandwidth",1,1,1,0,0,0
Performance Prediction for Convolutional Neural Network on Spark Cluster,2020,myung_performance_2020,"Data Input Size,Number of CPU Cores per Node,Number of Nodes,Memory Size per Node",0,1,1,0,0,0
A Performance Prediction Model for Spark Applications,2020,maros_machine_2019,"Framework Parameter Configuration,Number of Tasks,Task success rate,Completed Stages",1,0,0,1,0,0
Designing a MapReduce performance model in distributed heterogeneous platforms based on benchmarking approach,2020,gandomi_designing_2020,"Task Execution Time,Data Input Size,Data Output Size",0,1,0,1,0,0
Balance Resource Allocation for Spark Jobs Based on Prediction of the Optimal Resource,2020,hu_balance_2020,"Data Input Size,Framework Parameter Configuration,Workflow Structure (Spark DAG),Number of CPU Cores,Memory Size",1,1,1,0,0,0
Cross-Domain Workloads Performance Prediction via Runtime Metrics Transferring,2020,li_cross-domain_2020,"System Level Metrics,Historical Execution Time,VM Config",0,0,0,1,0,1
SPM: Modeling Spark Task Execution Time from the Sub-stage Perspective,2020,ataie_combined_2016,"Data Input Size,Task Scheduler Delay,(de)serialization time,Historical Execution Time,Garbage collection time,Shuffle R/W",1,1,0,1,0,1
On Machine Learning-based Stage-aware Performance Prediction of Spark Applications,2020,ye_machine_2020,"Number of CPU Cores per Node,Memory Size per Node,Number of Nodes,Data Input Size,Shuffle R/W",0,1,1,0,0,0
Performance prediction for data-driven workflows on apache spark,2020,gulino_performance_2020,"Input Data Profile,Input Parameters,Number of CPU Cores,Workflow Structure (Spark DAG),Memory Size",1,1,1,0,1,0
Bellamy: Reusing Performance Models for Distributed Dataflow Jobs Across Contexts,2021,scheinert_bellamy_2021,"Job parameters,""Node Type (Master, Slave)"",Data Input Size,Target dataset characteristics,Number of CPU Cores,Memory Size,Workload Type",0,1,1,0,1,0
Enel: Context-Aware Dynamic Scaling of Distributed Dataflow Jobs using Graph Propagation,2021,scheinert_enel_2021,"CPU Utilisation - Overall,Shuffle R/W,Data I/O,Ratio of memory spilled to disk to peak execution memory,Garbage collection time,Data Input Size,Input Parameters,Workload Type,hardware speciﬁcations / machine name",0,1,1,1,1,1
Efficient Performance Prediction for Apache Spark,2021,cheng_efficient_2021,"Data Input Size,Framework Parameter Configuration",1,1,0,0,0,0
Neural-based modeling for performance tuning of spark data analytics [arXiv],2021,zaouk_neural-based_2021,"Job Configuration,Processing Latency,Spark Time Metrics,CPU Utilisation - Overall,Network usage,I/O Usage,Input Parameters",0,0,0,1,1,0
Tuning configuration of apache spark on public clouds by combining multi-objective optimization and performance prediction model,2021,cheng_tuning_2021,"Framework Parameter Configuration,Number of Cloud Instances,Cloud Machine Type",1,0,0,0,0,1
A parallelization model for performance characterization of Spark Big Data jobs on Hadoop clusters,2021,ahmed_parallelization_2021,"Task Execution Time,I/O Time,Framework Parameter Configuration,Available Resources,Available Network Bandwidth",1,0,0,1,0,0
Machine-Learning Based Memory Prediction Model for Data Parallel Workloads in Apache Spark,2021,myung_machine-learning_2021,"Workload Type,Size of elements",1,1,0,0,1,0
An Enhanced Parallelisation Model for Performance Prediction of Apache Spark on a Multinode Hadoop Cluster,2021,ahmed_enhanced_2021,"Task Memory Requirement,Number of CPU Cores,Number of Nodes",0,0,1,1,0,0
A performance modeling-based HADOOP configuration tuning strategy,2022,jie_performance_2022,"Framework Parameter Configuration,Input Data,Workload Type",1,0,0,0,1,0
A Hybrid Machine Learning Approach for Performance Modeling of Cloud-Based Big Data Applications,2022,ataie_hybrid_2022,"Historical Execution Time,Number of Tasks,Job Data Size,Number of CPU Cores,Workflow Structure (Spark DAG)",1,0,1,1,0,0
MarVeLScaler: A Multi-View Learning-Based Auto-Scaling System for MapReduce,2022,li_marvelscaler_2022,"Number of Nodes,Memory Size per Node,Type of the storage medium,CPU Processing Power,Task Execution Time,Task success rate,Number of Tasks",1,0,1,1,0,0
A Machine Learning Approach for Predicting Execution Statistics of Spark Application,2022,sewal_machine_2022,"Number of Tasks,Historical Execution Time,Task I/O Read Cost,Task I/O Write Cost,Number of CPU Cores,Stage Execution Time,Task Execution Time",1,0,1,1,0,0
d-Simplexed: Adaptive Delaunay Triangulation or Performance Modeling and Prediction on Big Data Analytics,2022,chen_d-simplexed_2019,"Data Input Size,Number of CPU Cores,Memory Size",0,1,1,0,0,0
Phronesis: Efficient Performance Modeling for High-dimensional Configuration Tuning,2022,li_phronesis_2022,Framework Parameter Configuration,1,0,0,0,0,0
Cost-Aware Resource Recommendation for DAG-Based Big Data Workflows: An Apache Spark Case Study,2023,aseman-manzar_cost-aware_2022,"Number of Slots,Number of Job Stages,Workflow Structure (Spark DAG),Historical Execution Time,Start and Cleanup Time",1,0,0,1,0,0
A Novel Multi-Task Performance Prediction Model for Spark,2023,shen_novel_2023,"Spark History Logs,Framework Parameter Configuration,Historical Execution Time,CPU Utilisation - Overall,Memory Utilisation,Job Status,Ressource Utilisation Data,Task Execution Time",1,0,0,1,0,0
Fixed-Point Iteration Approach to Spark Scalable Performance Modeling and Evaluation,2023,karimian-aliabadi_fixed-point_2023,"Running Tasks,Completed Tasks,Available Resources",1,0,0,0,0,0
