
@inproceedings{scheinert_bellamy_2021,
	title = {Bellamy: Reusing Performance Models for Distributed Dataflow Jobs Across Contexts},
	url = {http://arxiv.org/abs/2107.13921},
	doi = {10.1109/Cluster48925.2021.00052},
	shorttitle = {Bellamy},
	abstract = {Distributed dataﬂow systems enable the use of clusters for scalable data analytics. However, selecting appropriate cluster resources for a processing job is often not straightforward. Performance models trained on historical executions of a concrete job are helpful in such situations, yet they are usually bound to a speciﬁc job execution context (e.g. node type, software versions, job parameters) due to the few considered input parameters. Even in case of slight context changes, such supportive models need to be retrained and cannot beneﬁt from historical execution data from related contexts.},
	pages = {261--270},
	booktitle = {2021 {IEEE} International Conference on Cluster Computing ({CLUSTER})},
	author = {Scheinert, Dominik and Thamsen, Lauritz and Zhu, Houkun and Will, Jonathan and Acker, Alexander and Wittkopp, Thorsten and Kao, Odej},
	urldate = {2023-11-10},
	date = {2021-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2107.13921 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
	file = {Scheinert et al. - 2021 - Bellamy Reusing Performance Models for Distributed Dataflow Jobs Across Contexts.pdf:C\:\\Users\\Alex\\Zotero\\storage\\NPI5ZKEI\\Scheinert et al. - 2021 - Bellamy Reusing Performance Models for Distributed Dataflow Jobs Across Contexts.pdf:application/pdf},
}

@inproceedings{wang_performance_2015,
	location = {New York, {NY}},
	title = {Performance Prediction for Apache Spark Platform},
	isbn = {978-1-4799-8937-9},
	url = {https://ieeexplore.ieee.org/document/7336160/},
	doi = {10.1109/HPCC-CSS-ICESS.2015.246},
	abstract = {Apache Spark is an open source distributed data processing platform that uses distributed memory abstraction to process large volume of data efﬁciently. However, performance of a particular job on Apache Spark platform can vary signiﬁcantly depending on the input data type and size, design and implementation of the algorithm, and computing capability, making it extremely difﬁcult to predict the performance metric of a job such as execution time, memory footprint, and I/O cost. To address this challenge, in this paper, we present a simulation driven prediction model that can predict job performance with high accuracy for Apache Spark platform. Speciﬁcally, as Apache spark jobs are often consist of multiple sequential stages, the presented prediction model simulates the execution of the actual job by using only a fraction of the input data, and collect execution traces (e.g., I/O overhead, memory consumption, execution time) to predict job performance for each execution stage individually. We evaluated our prediction framework using four real-life applications on a 13 node cluster, and experimental results show that the model can achieve high prediction accuracy.},
	eventtitle = {2015 {IEEE} 17th International Conference on High-Performance Computing and Communications; 2015 {IEEE} 7th International Symposium on Cyberspace Safety and Security; and 2015 {IEEE} 12th International Conference on Embedded Software and Systems},
	pages = {166--173},
	booktitle = {2015 {IEEE} 17th International Conference on High Performance Computing and Communications, 2015 {IEEE} 7th International Symposium on Cyberspace Safety and Security, and 2015 {IEEE} 12th International Conference on Embedded Software and Systems},
	publisher = {{IEEE}},
	author = {Wang, Kewen and Khan, Mohammad Maifi Hasan},
	urldate = {2024-01-29},
	date = {2015-08},
	langid = {english},
	keywords = {Spark},
	file = {Wang und Khan - 2015 - Performance Prediction for Apache Spark Platform.pdf:C\:\\Users\\Alex\\Zotero\\storage\\DK4P2W9S\\Wang und Khan - 2015 - Performance Prediction for Apache Spark Platform.pdf:application/pdf},
}

@article{khan_hadoop_2016,
	title = {Hadoop Performance Modeling for Job Estimation and Resource Provisioning},
	volume = {27},
	issn = {1045-9219},
	url = {http://ieeexplore.ieee.org/document/7045505/},
	doi = {10.1109/TPDS.2015.2405552},
	abstract = {{MapReduce} has become a major computing model for data intensive applications. Hadoop, an open source implementation of {MapReduce}, has been adopted by an increasingly growing user community. Cloud computing service providers such as Amazon {EC}2 Cloud offer the opportunities for Hadoop users to lease a certain amount of resources and pay for their use. However, a key challenge is that cloud service providers do not have a resource provisioning mechanism to satisfy user jobs with deadline requirements. Currently, it is solely the user’s responsibility to estimate the required amount of resources for running a job in the cloud. This paper presents a Hadoop job performance model that accurately estimates job completion time and further provisions the required amount of resources for a job to be completed within a deadline. The proposed model builds on historical job execution records and employs Locally Weighted Linear Regression ({LWLR}) technique to estimate the execution time of a job. Furthermore, it employs Lagrange Multipliers technique for resource provisioning to satisfy jobs with deadline requirements. The proposed model is initially evaluated on an in-house Hadoop cluster and subsequently evaluated in the Amazon {EC}2 Cloud. Experimental results show that the accuracy of the proposed model in job execution estimation is in the range of 94.97 and 95.51 percent, and jobs are completed within the required deadlines following on the resource provisioning scheme of the proposed model.},
	pages = {441--454},
	number = {2},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	shortjournal = {{IEEE} Trans. Parallel Distrib. Syst.},
	author = {Khan, Mukhtaj and Jin, Yong and Li, Maozhen and Xiang, Yang and Jiang, Changjun},
	urldate = {2024-01-29},
	date = {2016-02-01},
	langid = {english},
	file = {Khan et al. - 2016 - Hadoop Performance Modeling for Job Estimation and Resource Provisioning.pdf:C\:\\Users\\Alex\\Zotero\\storage\\KS4SIE7T\\Khan et al. - 2016 - Hadoop Performance Modeling for Job Estimation and Resource Provisioning.pdf:application/pdf},
}

@inproceedings{yu_datasize-aware_2018,
	location = {Williamsburg {VA} {USA}},
	title = {Datasize-Aware High Dimensional Configurations Auto-Tuning of In-Memory Cluster Computing},
	isbn = {978-1-4503-4911-6},
	url = {https://dl.acm.org/doi/10.1145/3173162.3173187},
	doi = {10.1145/3173162.3173187},
	abstract = {In-Memory cluster Computing ({IMC}) frameworks (e.g., Spark) have become increasingly important because they typically achieve more than 10× speedups over the traditional On-Disk cluster Computing ({ODC}) frameworks for iterative and interactive applications. Like {ODC}, {IMC} frameworks typically run the same given programs repeatedly on a given cluster with similar input dataset size each time. It is challenging to build performance model for {IMC} program because: 1) the performance of {IMC} programs is more sensitive to the size of input dataset, which is known to be difficult to be incorporated into a performance model due to its complex effects on performance; 2) the number of performance-critical configuration parameters in {IMC} is much larger than {ODC} (more than 40 vs. around 10), the high dimensionality requires more sophisticated models to achieve high accuracy.},
	eventtitle = {{ASPLOS} '18: Architectural Support for Programming Languages and Operating Systems},
	pages = {564--577},
	booktitle = {Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems},
	publisher = {{ACM}},
	author = {Yu, Zhibin and Bei, Zhendong and Qian, Xuehai},
	urldate = {2024-01-29},
	date = {2018-03-19},
	langid = {english},
	keywords = {{HiBench}},
	file = {Yu et al. - 2018 - Datasize-Aware High Dimensional Configurations Auto-Tuning of In-Memory Cluster Computing.pdf:C\:\\Users\\Alex\\Zotero\\storage\\J6ALN8CI\\Yu et al. - 2018 - Datasize-Aware High Dimensional Configurations Auto-Tuning of In-Memory Cluster Computing.pdf:application/pdf},
}

@article{bei_rfhoc_2016,
	title = {{RFHOC}: A Random-Forest Approach to Auto-Tuning Hadoop's Configuration},
	volume = {27},
	issn = {1045-9219},
	url = {http://ieeexplore.ieee.org/document/7132754/},
	doi = {10.1109/TPDS.2015.2449299},
	shorttitle = {{RFHOC}},
	abstract = {Hadoop is a widely-used implementation framework of the {MapReduce} programming model for large-scale data processing. Hadoop performance however is signiﬁcantly affected by the settings of the Hadoop conﬁguration parameters. Unfortunately, manually tuning these parameters is very time-consuming, if at all practical. This paper proposes an approach, called {RFHOC}, to automatically tune the Hadoop conﬁguration parameters for optimized performance for a given application running on a given cluster. {RFHOC} constructs two ensembles of performance models using a random-forest approach for the map and reduce stage respectively. Leveraging these models, {RFHOC} employs a genetic algorithm to automatically search the Hadoop conﬁguration space. The evaluation of {RFHOC} using ﬁve typical Hadoop programs, each with ﬁve different input data sets, shows that it achieves a performance speedup by a factor of 2.11  on average and up to 7.4  over the recently proposed cost-based optimization ({CBO}) approach. In addition, {RFHOC}’s performance beneﬁt increases with input data set size.},
	pages = {1470--1483},
	number = {5},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	shortjournal = {{IEEE} Trans. Parallel Distrib. Syst.},
	author = {Bei, Zhendong and Yu, Zhibin and Zhang, Huiling and Xiong, Wen and Xu, Chengzhong and Eeckhout, Lieven and Feng, Shengzhong},
	urldate = {2024-01-29},
	date = {2016-05-01},
	langid = {english},
	keywords = {{HiBench}},
	file = {Bei et al. - 2016 - RFHOC A Random-Forest Approach to Auto-Tuning Hadoop's Configuration.pdf:C\:\\Users\\Alex\\Zotero\\storage\\3WTNS6J5\\Bei et al. - 2016 - RFHOC A Random-Forest Approach to Auto-Tuning Hadoop's Configuration.pdf:application/pdf},
}

@article{glushkova_mapreduce_2019,
	title = {Mapreduce performance model for Hadoop 2.x},
	volume = {79},
	issn = {03064379},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306437917304659},
	doi = {10.1016/j.is.2017.11.006},
	abstract = {{MapReduce} is a popular programming model for distributed processing of large data sets. Apache Hadoop is one of the most common open-source implementations of such paradigm. Performance analysis of concurrent job executions has been recognized as a challenging problem, at the same time, that may provide reasonably accurate job response time estimation at signiﬁcantly lower cost than experimental evaluation of real setups. In this paper, we tackle the challenge of deﬁning {MapReduce} performance model for Hadoop 2.x. While there are several eﬃcient approaches for modeling the performance of {MapReduce} workloads in Hadoop 1.x, they could not be applied to Hadoop 2.x due to fundamental architectural changes and dynamic resource allocation in Hadoop 2.x. Thus, the proposed solution is based on an existing performance model for Hadoop 1.x, but taking into consideration architectural changes and capturing the execution ﬂow of a {MapReduce} job by using queuing network model. This way, the cost model reﬂects the intra-job synchronization constraints that occur due the contention at shared resources. The accuracy of our solution is validated via comparison of our model estimates against measurements in a real Hadoop 2.x setup.},
	pages = {32--43},
	journaltitle = {Information Systems},
	shortjournal = {Information Systems},
	author = {Glushkova, Daria and Jovanovic, Petar and Abelló, Alberto},
	urldate = {2024-01-30},
	date = {2019-01},
	langid = {english},
	file = {Glushkova et al. - 2019 - Mapreduce performance model for Hadoop 2.x.pdf:C\:\\Users\\Alex\\Zotero\\storage\\WS93E54Z\\Glushkova et al. - 2019 - Mapreduce performance model for Hadoop 2.x.pdf:application/pdf},
}

@article{xu_cost-effective_2019,
	title = {Cost-Effective Cloud Server Provisioning for Predictable Performance of Big Data Analytics},
	volume = {30},
	issn = {1045-9219, 1558-2183, 2161-9883},
	url = {https://ieeexplore.ieee.org/document/8478347/},
	doi = {10.1109/TPDS.2018.2873397},
	abstract = {Cloud datacenters are underutilized due to server over-provisioning. To increase datacenter utilization, cloud providers offer users an option to run workloads such as big data analytics on the underutilized resources, in the form of cheap yet revocable transient servers (e.g., {EC}2 spot instances, {GCE} preemptible instances). Though at highly reduced prices, deploying big data analytics on the unstable cloud transient servers can severely degrade the job performance due to instance revocations. To tackle this issue, this paper proposes {iSpot}, a cost-effective transient server provisioning framework for achieving predictable performance in the cloud, by focusing on Spark as a representative Directed Acyclic Graph ({DAG})-style big data analytics workload. It ﬁrst identiﬁes the stable cloud transient servers during the job execution by devising an accurate Long Short-Term Memory ({LSTM})-based price prediction method. Leveraging automatic job proﬁling and the acquired {DAG} information of stages, we further build an analytical performance model and present a lightweight critical data checkpointing mechanism for Spark, to enable our design of {iSpot} provisioning strategy for guaranteeing the job performance on stable transient servers. Extensive prototype experiments on both {EC}2 spot instances and {GCE} preemptible instances demonstrate that, {iSpot} is able to guarantee the performance of big data analytics running on cloud transient servers while reducing the job budget by up to 83.8 percent in comparison to the state-of-the-art server provisioning strategies, yet with acceptable runtime overhead.},
	pages = {1036--1051},
	number = {5},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	shortjournal = {{IEEE} Trans. Parallel Distrib. Syst.},
	author = {Xu, Fei and Zheng, Haoyue and Jiang, Huan and Shao, Wujie and Liu, Haikun and Zhou, Zhi},
	urldate = {2024-01-30},
	date = {2019-05-01},
	langid = {english},
	file = {Xu et al. - 2019 - Cost-Effective Cloud Server Provisioning for Predictable Performance of Big Data Analytics.pdf:C\:\\Users\\Alex\\Zotero\\storage\\JYIYPB75\\Xu et al. - 2019 - Cost-Effective Cloud Server Provisioning for Predictable Performance of Big Data Analytics.pdf:application/pdf},
}

@inproceedings{islam_dspark_2017,
	location = {Auckland},
	title = {{dSpark}: Deadline-Based Resource Allocation for Big Data Applications in Apache Spark},
	isbn = {978-1-5386-2686-3},
	url = {http://ieeexplore.ieee.org/document/8109126/},
	doi = {10.1109/eScience.2017.21},
	shorttitle = {{dSpark}},
	abstract = {Large-scale data processing framework like Apache Spark is becoming more popular to process large amounts of data either in a local or a cloud deployed cluster. When an application is deployed in a Spark cluster, all the resources are allocated to it unless users manually set a limit on the available resources. In addition, it is not possible to impose any user-speciﬁc constraints and minimize the cost of running applications. In this paper, we present {dSpark}, a lightweight, pluggable resource allocation framework for Apache Spark. In {dSpark}, we have modelled the application completion time with respect to the number of executors and application input/iteration. This model is further used in our proposed resource allocation model where a deadlinebased, cost-efﬁcient resource allocation scheme can be selected for any application. As opposed to the existing frameworks that focus more on modelling the number of {VMs} to use for an application, we have modelled both the application cost and completion time with respect to executors, hence providing a ﬁnegrained resource allocation scheme. In addition, users do not need to specify any application types in {dSpark}. We have evaluated our proposed framework through extensive experimentation, which shows signiﬁcant performance beneﬁts. The application completion time prediction model has a mean relative error ({RE}) less than 7\% for different types of applications. Furthermore, we have shown that our proposed resource allocation model minimizes the cost of running applications and selects effective resource allocation schemes under varying user-speciﬁc deadlines.},
	eventtitle = {2017 {IEEE} 13th International Conference on e-Science (e-Science)},
	pages = {89--98},
	booktitle = {2017 {IEEE} 13th International Conference on e-Science (e-Science)},
	publisher = {{IEEE}},
	author = {Islam, Muhammed Tawfiqul and Karunasekera, Shanika and Buyya, Rajkumar},
	urldate = {2024-01-31},
	date = {2017-10},
	langid = {english},
	file = {Islam et al. - 2017 - dSpark Deadline-Based Resource Allocation for Big Data Applications in Apache Spark.pdf:C\:\\Users\\Alex\\Zotero\\storage\\GQLVQHB6\\Islam et al. - 2017 - dSpark Deadline-Based Resource Allocation for Big Data Applications in Apache Spark.pdf:application/pdf},
}

@inproceedings{gandhi_autoscaling_2016,
	location = {Berlin, Germany},
	title = {Autoscaling for Hadoop Clusters},
	isbn = {978-1-5090-1961-8},
	url = {http://ieeexplore.ieee.org/document/7484170/},
	doi = {10.1109/IC2E.2016.11},
	abstract = {Unforeseen events such as node failures and resource contention can have a severe impact on the performance of data processing frameworks, such as Hadoop, especially in cloud environments where such incidents are common. {SLA} compliance in the presence of such events requires the ability to quickly and dynamically resize infrastructure resources. Unfortunately, the distributed and stateful nature of data processing frameworks makes it challenging to accurately scale the system at run-time. In this paper, we present the design and implementation of a model-driven autoscaling solution for Hadoop clusters. We ﬁrst develop novel gray-box performance models for Hadoop workloads that speciﬁcally relate job execution times to resource allocation and workload parameters. We then employ these models to dynamically determine the resources required to successfully complete the Hadoop jobs as per the user-speciﬁed {SLA} under various scenarios including node failures and multi-job executions. Our experimental results on three different Hadoop cloud clusters and across different workloads demonstrate the efﬁcacy of our models and highlight their autoscaling capabilities.},
	eventtitle = {2016 {IEEE} International Conference on Cloud Engineering ({IC}2E)},
	pages = {109--118},
	booktitle = {2016 {IEEE} International Conference on Cloud Engineering ({IC}2E)},
	publisher = {{IEEE}},
	author = {Gandhi, Anshul and Thota, Sidhartha and Dube, Parijat and Kochut, Andrzej and Zhang, Li},
	urldate = {2024-01-31},
	date = {2016-04},
	langid = {english},
	file = {Gandhi et al. - 2016 - Autoscaling for Hadoop Clusters.pdf:C\:\\Users\\Alex\\Zotero\\storage\\XUET4LM5\\Gandhi et al. - 2016 - Autoscaling for Hadoop Clusters.pdf:application/pdf},
}

@article{ramanathan_towards_2019,
	title = {Towards optimal resource provisioning for Hadoop-{MapReduce} jobs using scale-out strategy and its performance analysis in private cloud environment},
	volume = {22},
	issn = {1386-7857, 1573-7543},
	url = {http://link.springer.com/10.1007/s10586-018-2234-8},
	doi = {10.1007/s10586-018-2234-8},
	abstract = {Cloud computing always provides {IT} resources on demand basis, without additional waiting time. Therefore, data analytics is one of the most signiﬁcant areas that can be beneﬁted from Cloud Computing. {MapReduce} programs in the cloud computing to optimize the resource provisioning and ﬁnish the {MapReduce} jobs with quantiﬁed time. The efﬁcacy as well as the accuracy of performance of the performance model based on regression used for predicting the {MapReduce} job completion time has been suggested in our {OpenStack} private cloud Hadoop cluster using linear regression method. In order to satisfy the user jobs with deadline requirements, Cloud service providers do not have a resource provisioning technique or polices. The contemporary system requires a cloud user to estimate the needed quantity of resources for running jobs in the cloud. Our proposed scalability strategy of Scale-Out methods used to obtain the accurate prediction of job completion times through our experimental results shows the performance level of {MapReduce} benchmark in the open stack private cloud. The regression based performance model predicting and evaluating the execution time of 5 popular {MapReduce} benchmark applications over our private cloud environment with better resource utilization which depicts 99\% of accuracy results.},
	pages = {14061--14071},
	issue = {S6},
	journaltitle = {Cluster Computing},
	shortjournal = {Cluster Comput},
	author = {Ramanathan, Ramakrishnan and Latha, B.},
	urldate = {2024-02-05},
	date = {2019-11},
	langid = {english},
	file = {Ramanathan und Latha - 2019 - Towards optimal resource provisioning for Hadoop-MapReduce jobs using scale-out strategy and its per.pdf:C\:\\Users\\Alex\\Zotero\\storage\\CVJJVBLD\\Ramanathan und Latha - 2019 - Towards optimal resource provisioning for Hadoop-MapReduce jobs using scale-out strategy and its per.pdf:application/pdf},
}

@article{cheng_efficient_2021,
	title = {Efficient Performance Prediction for Apache Spark},
	volume = {149},
	issn = {07437315},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0743731520303993},
	doi = {10.1016/j.jpdc.2020.10.010},
	abstract = {Spark is a more efficient distributed big data processing framework following Hadoop. It provides users with more than 180 adjustable configuration parameters, and how to choose the optimal configuration automatically to make the Spark application run effectively is challenging. The key to address the above challenge is having the ability to predict the performance of Spark applications in different configurations. This paper proposes a new approach based on Adaboost, which can efficiently and accurately predict the performance of a given application with a given Spark configuration. In our approach, Adaboost is used to build a set of performance models at the stage-level for Spark. To minimize the overhead of the modeling, we use the classic projective sampling, a data mining technique that allows us to collect as few training samples as possible while meeting the accuracy requirements. We evaluate the proposed approach on six typical Spark benchmarks with five input datasets. The experimental results show that our approach is less than the previously proposed approach in prediction error and cost.},
	pages = {40--51},
	journaltitle = {Journal of Parallel and Distributed Computing},
	shortjournal = {Journal of Parallel and Distributed Computing},
	author = {Cheng, Guoli and Ying, Shi and Wang, Bingming and Li, Yuhang},
	urldate = {2024-02-05},
	date = {2021-03},
	langid = {english},
	file = {Cheng et al. - 2021 - Efficient Performance Prediction for Apache Spark.pdf:C\:\\Users\\Alex\\Zotero\\storage\\LXVIAB9E\\Cheng et al. - 2021 - Efficient Performance Prediction for Apache Spark.pdf:application/pdf},
}

@article{chao_gray-box_2018,
	title = {A gray-box performance model for Apache Spark},
	volume = {89},
	issn = {0167739X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X17323233},
	doi = {10.1016/j.future.2018.06.032},
	abstract = {Apache Spark is a powerful open source data processing platform. It is getting more and more popular with the growing need of processing massive amounts of data. A performance prediction model not only helps administrators to have a better understanding of system behavior, but also is useful in performance tuning. However, considering the complex application processing mechanism of Spark, it is not an easy job to model the relationship between system performance and configuration settings.},
	pages = {58--67},
	journaltitle = {Future Generation Computer Systems},
	shortjournal = {Future Generation Computer Systems},
	author = {Chao, Zemin and Shi, Shengfei and Gao, Hong and Luo, Jizhou and Wang, Hongzhi},
	urldate = {2024-02-05},
	date = {2018-12},
	langid = {english},
	file = {Chao et al. - 2018 - A gray-box performance model for Apache Spark.pdf:C\:\\Users\\Alex\\Zotero\\storage\\44L9C3UY\\Chao et al. - 2018 - A gray-box performance model for Apache Spark.pdf:application/pdf},
}

@article{chen_d-simplexed_2019,
	title = {d-Simplexed: Adaptive Delaunay Triangulation for Performance Modeling and Prediction on Big Data Analytics},
	issn = {2332-7790, 2372-2096},
	url = {https://ieeexplore.ieee.org/document/8878273/},
	doi = {10.1109/TBDATA.2019.2948338},
	shorttitle = {d-Simplexed},
	abstract = {Big Data processing systems (e.g., Spark) have a number of resource conﬁguration parameters, such as memory size, {CPU} allocation, and the number of running nodes. Regular users and even expert administrators struggle to understand the mutual relation between different parameter conﬁgurations and the overall performance of the system. In this paper, we address this challenge by proposing a performance prediction framework, called d-Simplexed, to build performance models with varied conﬁgurable parameters on Spark. We take inspiration from the ﬁeld of Computational Geometry to construct a d-dimensional mesh using Delaunay Triangulation over a selected set of features. From this mesh, we predict execution time for various feature conﬁgurations. To minimize the time and resources in building a bootstrap model with a large number of conﬁguration values, we propose an adaptive sampling technique to allow us to collect as few training points as required. Our evaluation on a cluster of computers using {WordCount}, {PageRank}, Kmeans, and Join workloads in {HiBench} benchmarking suites shows that we can achieve less than 5 percent error rate for estimation accuracy by sampling less than 1 percent of data.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Big Data},
	shortjournal = {{IEEE} Trans. Big Data},
	author = {Chen, Yuxing and Goetsch, Peter and Hoque, Mohammad A. and Lu, Jiaheng and Tarkoma, Sasu},
	urldate = {2024-02-05},
	date = {2019},
	langid = {english},
	file = {Chen et al. - 2019 - d-Simplexed Adaptive Delaunay Triangulation for Performance Modeling and Prediction on Big Data Ana.pdf:C\:\\Users\\Alex\\Zotero\\storage\\PNMDPMLN\\Chen et al. - 2019 - d-Simplexed Adaptive Delaunay Triangulation for Performance Modeling and Prediction on Big Data Ana.pdf:application/pdf},
}

@article{hu_balance_2020,
	title = {Balance resource allocation for spark jobs based on prediction of the optimal resource},
	volume = {25},
	issn = {1007-0214},
	url = {https://ieeexplore.ieee.org/document/8954867/},
	doi = {10.26599/TST.2019.9010054},
	abstract = {Apache Spark provides a well-known {MapReduce} computing framework, aiming to fast-process big data analytics in data-parallel manners. With this platform, large input data are divided into data partitions. Each data partition is processed by multiple computation tasks concurrently. Outputs of these computation tasks are transferred among multiple computers via the network. However, such a distributed computing framework suffers from system overheads, inevitably caused by communication and disk I/O operations. System overheads take up a large proportion of the Job Completion Time ({JCT}). We observed that excessive computational resources incurs considerable system overheads, prolonging the {JCT}. The over-allocation of individual jobs not only prolongs their own {JCTs}, but also likely makes other jobs suffer from under-allocation. Thus, the average {JCT} is suboptimal, too. To address this problem, we propose a prediction model to estimate the changing {JCT} of a single Spark job. With the support of the prediction method, we designed a heuristic algorithm to balance the resource allocation of multiple Spark jobs, aiming to minimize the average {JCT} in multiple-job cases. We implemented the prediction model and resource allocation method in {ReB}, a Resource-Balancer based on Apache Spark. Experimental results showed that {ReB} signiﬁcantly outperformed the traditional max-min fairness and shortest-job-optimal methods. The average {JCT} was decreased by around 10\%–30\% compared to the existing solutions.},
	pages = {487--497},
	number = {4},
	journaltitle = {Tsinghua Science and Technology},
	shortjournal = {Tinshhua Sci. Technol.},
	author = {Hu, Zhiyao and Li, Dongsheng and Guo, Deke},
	urldate = {2024-02-05},
	date = {2020-08},
	langid = {english},
	file = {Hu et al. - 2020 - Balance resource allocation for spark jobs based on prediction of the optimal resource.pdf:C\:\\Users\\Alex\\Zotero\\storage\\U3MW2BH6\\Hu et al. - 2020 - Balance resource allocation for spark jobs based on prediction of the optimal resource.pdf:application/pdf},
}

@inproceedings{krob_model-based_2017,
	location = {Banff, {AB}},
	title = {Model-Based Performance Evaluation of Batch and Stream Applications for Big Data},
	isbn = {978-1-5386-2764-8},
	url = {http://ieeexplore.ieee.org/document/8107434/},
	doi = {10.1109/MASCOTS.2017.21},
	abstract = {Batch and stream processing represent the two main approaches implemented by big data systems such as Apache Spark and Apache Flink. Although only stream applications are intended to satisfy real-time requirements, both approaches are required to meet certain response time constraints. In addition, cluster architectures continuously expand and computing resources constitute high investments and expenses for organizations. Therefore, planning required capacities and predicting response times is crucial. In this work, we present a performance modeling and simulation approach by using and extending the Palladio component model. We predict performance metrics of batch and stream applications and its underlying processing systems by the example of Apache Spark on Apache Hadoop. Whereas most related work concentrates on one speciﬁc processing technique and focuses on the metric response time, we propose a general approach and consider the utilization of resources as well. In different experiments we evaluated our approach using applications and data workloads of the {HiBench} benchmark suite. The results indicate accurate predictions for upscaling cluster sizes as well as workloads with errors less than 18\%.},
	eventtitle = {2017 {IEEE} 25th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems ({MASCOTS})},
	pages = {80--86},
	booktitle = {2017 {IEEE} 25th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems ({MASCOTS})},
	publisher = {{IEEE}},
	author = {{KroB}, Johannes and Krcmar, Helmut},
	urldate = {2024-02-07},
	date = {2017-09},
	langid = {english},
	file = {KroB und Krcmar - 2017 - Model-Based Performance Evaluation of Batch and Stream Applications for Big Data.pdf:C\:\\Users\\Alex\\Zotero\\storage\\7D4AKWJV\\KroB und Krcmar - 2017 - Model-Based Performance Evaluation of Batch and Stream Applications for Big Data.pdf:application/pdf},
}

@article{li_measuring_2017,
	title = {Measuring Scale-Up and Scale-Out Hadoop with Remote and Local File Systems and Selecting the Best Platform},
	volume = {28},
	issn = {1045-9219},
	url = {http://ieeexplore.ieee.org/document/7940040/},
	doi = {10.1109/TPDS.2017.2712635},
	abstract = {{MapReduce} is a popular computing model for parallel data processing on large-scale datasets, which can vary from gigabytes to terabytes and petabytes. Though Hadoop {MapReduce} normally uses Hadoop Distributed File System ({HDFS}) local ﬁle system, it can be conﬁgured to use a remote ﬁle system. Then, an interesting question is raised: for a given application, which is the best running platform among the different combinations of scale-up and scale-out Hadoop with remote and local ﬁle systems. However, there has been no previous research on how different types of applications (e.g., {CPU}-intensive, data-intensive) with different characteristics (e.g., input data size) can beneﬁt from the different platforms. Thus, in this paper, we conduct a comprehensive performance measurement of different applications on scale-up and scale-out clusters conﬁgured with {HDFS} and a remote ﬁle system (i.e., {OFS}), respectively. We identify and study how different job characteristics (e.g., input data size, the number of ﬁle reads/writes, and the amount of computations) affect the performance of different applications on the different platforms. Based on the measurement results, we also propose a performance prediction model to help users select the best platforms that lead to the minimum latency. Our evaluation using a Facebook workload trace demonstrates the effectiveness of our prediction model. This study is expected to provide a guidance for users to choose the best platform to run different applications with different characteristics in the environment that provides both remote and local storage, such as {HPC} cluster and cloud environment.},
	pages = {3201--3214},
	number = {11},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	shortjournal = {{IEEE} Trans. Parallel Distrib. Syst.},
	author = {Li, Zhuozhao and Shen, Haiying},
	urldate = {2024-02-07},
	date = {2017-11-01},
	langid = {english},
	file = {Li und Shen - 2017 - Measuring Scale-Up and Scale-Out Hadoop with Remote and Local File Systems and Selecting the Best Pl.pdf:C\:\\Users\\Alex\\Zotero\\storage\\SWDELN32\\Li und Shen - 2017 - Measuring Scale-Up and Scale-Out Hadoop with Remote and Local File Systems and Selecting the Best Pl.pdf:application/pdf},
}

@inproceedings{thamsen_continuously_2016,
	location = {Nara, Japan},
	title = {Continuously Improving the Resource Utilization of Iterative Parallel Dataflows},
	isbn = {978-1-5090-3686-8},
	url = {http://ieeexplore.ieee.org/document/7756200/},
	doi = {10.1109/ICDCSW.2016.20},
	abstract = {Parallel dataﬂow systems like Apache Flink allow analysis of large datasets with iterative programs. However, allocating a cost-effective set of resources for such jobs is a difﬁcult task as the resource utilization depends on many factors such as dataset size, key value distributions, computational complexity of programs, and the underlying hardware. What’s more, some of these factors are not well known before the execution. There are, for example, often no data statistics such as key value distributions available beforehand.},
	eventtitle = {2016 {IEEE} 36th International Conference on Distributed Computing Systems Workshops ({ICDCSW})},
	pages = {1--6},
	booktitle = {2016 {IEEE} 36th International Conference on Distributed Computing Systems Workshops ({ICDCSW})},
	publisher = {{IEEE}},
	author = {Thamsen, Lauritz and Renner, Thomas and Kao, Odej},
	urldate = {2024-02-08},
	date = {2016-06},
	langid = {english},
	file = {Thamsen et al. - 2016 - Continuously Improving the Resource Utilization of Iterative Parallel Dataflows.pdf:C\:\\Users\\Alex\\Zotero\\storage\\8K67NVDQ\\Thamsen et al. - 2016 - Continuously Improving the Resource Utilization of Iterative Parallel Dataflows.pdf:application/pdf},
}

@article{gianniti_fluid_2017,
	title = {Fluid Petri Nets for the Performance Evaluation of {MapReduce} and Spark Applications},
	volume = {44},
	issn = {0163-5999},
	url = {https://dl.acm.org/doi/10.1145/3092819.3092824},
	doi = {10.1145/3092819.3092824},
	abstract = {Big Data applications allow to successfully analyze large amounts of data not necessarily structured, though at the same time they present new challenges. For example, predicting the performance of frameworks such as Hadoop and Spark can be a costly task, hence the necessity to provide models that can be a valuable support for designers and developers. Big Data systems are becoming a central force in society and the use of models can also enable the development of intelligent systems providing Quality of Service ({QoS}) guarantees to their users through runtime system reconﬁguration. This paper provides a new contribution in studying a novel modeling approach based on ﬂuid Petri nets to predict {MapReduce} and Spark applications execution time which is suitable for runtime performance prediction.},
	pages = {23--36},
	number = {4},
	journaltitle = {{ACM} {SIGMETRICS} Performance Evaluation Review},
	shortjournal = {{SIGMETRICS} Perform. Eval. Rev.},
	author = {Gianniti, Eugenio and Rizzi, Alessandro Maria and Barbierato, Enrico and Gribaudo, Marco and Ardagna, Danilo},
	urldate = {2024-02-08},
	date = {2017-05-10},
	langid = {english},
	file = {Gianniti et al. - 2017 - Fluid Petri Nets for the Performance Evaluation of MapReduce and Spark Applications.pdf:C\:\\Users\\Alex\\Zotero\\storage\\GCR46WZX\\Gianniti et al. - 2017 - Fluid Petri Nets for the Performance Evaluation of MapReduce and Spark Applications.pdf:application/pdf},
}

@inproceedings{lee_hadoop_2016,
	location = {Wurzburg},
	title = {Hadoop Performance Self-Tuning Using a Fuzzy-Prediction Approach},
	isbn = {978-1-5090-1654-9},
	url = {http://ieeexplore.ieee.org/document/7573116/},
	doi = {10.1109/ICAC.2016.52},
	abstract = {The Apache Hadoop framework (currently known as {YARN}) is a widely used open-source implementation of {MapReduce} ({MR}). Manual tuning of Hadoop performance is hard and time-consuming so several self-tuning approaches have been proposed. This paper proposes an approach that avoids problems of previous self-tuning approaches based on performance models or resource usage, namely 1) need for a time-consuming training phase, typically offline, 2) unsuitability for Hadoop environments with concurrently running {MR} jobs, and 3) need for modification of the Hadoop framework itself. The proposed approach uses a fuzzyprediction controller for self-optimization of the number of concurrent {MR} jobs. The fuzzy-prediction controller learns from past and current resource usage of {MR} jobs and from the number of concurrent tasks. It both uses and constructs rules in real time to predict the resource usage and the number of concurrent tasks. It does not require offline training or any modification of either the {MR} jobs or the Hadoop framework. The predicted values are used to dynamically control the number of concurrent {ApplicationMasters} ({AMs}) (i.e., {MR} jobs in {RUNNING} state). Experimental evaluation of the proposed approach on a 7-node cluster (1 master node and 6 slave nodes) running 30-job sequences combining three different types of {MR} jobs (Terasort, Grep and Wordcount) showed up to 29\% performance improvement over Hadoop default configurations. The new approach improves the aggregate performance of {MR} jobs by adjusting a single {YARN} parameter.},
	eventtitle = {2016 {IEEE} International Conference on Autonomic Computing ({ICAC})},
	pages = {55--64},
	booktitle = {2016 {IEEE} International Conference on Autonomic Computing ({ICAC})},
	publisher = {{IEEE}},
	author = {Lee, Gil Jae and Fortes, Jose A. B.},
	urldate = {2024-02-08},
	date = {2016-07},
	langid = {english},
	file = {Lee und Fortes - 2016 - Hadoop Performance Self-Tuning Using a Fuzzy-Prediction Approach.pdf:C\:\\Users\\Alex\\Zotero\\storage\\SZ3BMY79\\Lee und Fortes - 2016 - Hadoop Performance Self-Tuning Using a Fuzzy-Prediction Approach.pdf:application/pdf},
}

@article{karimian-aliabadi_analytical_2019,
	title = {Analytical composite performance models for Big Data applications},
	volume = {142},
	issn = {10848045},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1084804519302061},
	doi = {10.1016/j.jnca.2019.06.009},
	abstract = {Recent years witnessed a steep rise in data generation and, consequently, the widespread adoption of software solutions able to support data-intensive applications. Many companies currently engage in data-intensive processes, however, fully embracing a data-driven paradigm is still cumbersome, and establishing a productionready and ﬁne-tuned deployment is time-consuming. This situation calls for innovative models and techniques to streamline the process of deployment conﬁguration for Big Data applications. Moreover, many companies are using Cloud deployed clusters, which represent a cost-eﬀective alternative to installation on premises. Accurate and fast prediction of the execution time of a Big Data application helps improving design time decisions, reduces Cloud over allocation charges, and assists budget management. In this paper, analytical models based on Stochastic Activity Networks ({SANs}) are proposed to accurately model the execution of Hadoop, Tez and Spark applications, i.e., the most referred frameworks to support Big Data analyses. The proposed {SANs} model these applications together with the underlying cluster in order to accurately estimate the execution time. We evaluate the accuracy of the proposed models over the {TPC}-{DS} industry benchmark across diﬀerent conﬁgurations. Results obtained by numerically solving the {SAN} models show an average error of 4.5\%, 5.8\%, and 2.7\% in estimating the execution time of {MR}, Tez, and Spark applications, respectively, against the data gathered from the experiments demonstrating higher accuracy compared with the state-of-the-art. Moreover, the time required to solve the proposed models is lower than the simulation time of the previously presented approaches in this area.},
	pages = {63--75},
	journaltitle = {Journal of Network and Computer Applications},
	shortjournal = {Journal of Network and Computer Applications},
	author = {Karimian-Aliabadi, Soroush and Ardagna, Danilo and Entezari-Maleki, Reza and Gianniti, Eugenio and Movaghar, Ali},
	urldate = {2024-02-09},
	date = {2019-09},
	langid = {english},
	file = {Karimian-Aliabadi et al. - 2019 - Analytical composite performance models for Big Data applications.pdf:C\:\\Users\\Alex\\Zotero\\storage\\2PNRUTET\\Karimian-Aliabadi et al. - 2019 - Analytical composite performance models for Big Data applications.pdf:application/pdf},
}

@inproceedings{luo_performance_2016,
	location = {Macau, China},
	title = {Performance Modeling for Spark Using {SVM}},
	isbn = {978-1-5090-3555-7},
	url = {http://ieeexplore.ieee.org/document/7979892/},
	doi = {10.1109/CCBD.2016.034},
	abstract = {At present, Spark is widely used in a number of enterprises. Although Spark is much faster than Hadoop for some applications, its conﬁguration parameters can have a great impact on its performance due to the large number of the parameters, interaction between them, and various characteristics of applications as well. Unfortunately, there is not yet any research conducted to predict the performance of Spark based on its conﬁguration sets.},
	eventtitle = {2016 7th International Conference on Cloud Computing and Big Data ({CCBD})},
	pages = {127--131},
	booktitle = {2016 7th International Conference on Cloud Computing and Big Data ({CCBD})},
	publisher = {{IEEE}},
	author = {Luo, Ni and Yu, Zhibin and Bei, Zhendong and Xu, Chengzhong and Jiang, Chuntao and Lin, Lingfeng},
	urldate = {2024-02-09},
	date = {2016-11},
	langid = {english},
	file = {Luo et al. - 2016 - Performance Modeling for Spark Using SVM.pdf:C\:\\Users\\Alex\\Zotero\\storage\\RY96FCGU\\Luo et al. - 2016 - Performance Modeling for Spark Using SVM.pdf:application/pdf},
}

@article{cheng_tuning_2021,
	title = {Tuning configuration of apache spark on public clouds by combining multi-objective optimization and performance prediction model},
	volume = {180},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121221001254},
	doi = {10.1016/j.jss.2021.111028},
	abstract = {Choosing the right configuration for Spark deployed in the public cloud to ensure the efficient running of periodic jobs is hard, because there can be a huge configuration space to explore which is composed of numerous performance-related parameters in different dimensions (e.g., applicationlevel and cloud-level). Choosing poorly will not only significantly degrade performance but may also lead to greater overhead. However, automatically searching for the optimal configuration of various applications to trade-off performance and cost is challenging. To address this issue, we propose a new optimal configuration search algorithm named {AB}-{MOEA}/D by combining multi-objective optimization algorithm and performance prediction model. {AB}-{MOEA}/D uses a decomposition-based multi-objective optimization algorithm to find the configuration with the objective of minimizing the execution time and cost, where the performance model constructed on the Adaboost algorithm is used to evaluate the fitness of each candidate configuration. Besides, we also present the configuration automatic tuning system with {AB}-{MOEA}/D as the optimization engine. The experimental results on six benchmarks with five data sets show that {AB}-{MOEA}/D significantly outperforms the previous work in terms of execution time and cost, with average improvements of approximately 35 and 40 percent.},
	pages = {111028},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Cheng, Guoli and Ying, Shi and Wang, Bingming},
	urldate = {2024-02-09},
	date = {2021-10},
	langid = {english},
	file = {Cheng et al. - 2021 - Tuning configuration of apache spark on public clouds by combining multi-objective optimization and .pdf:C\:\\Users\\Alex\\Zotero\\storage\\I692GW57\\Cheng et al. - 2021 - Tuning configuration of apache spark on public clouds by combining multi-objective optimization and .pdf:application/pdf},
}

@inproceedings{thamsen_ellis_2017,
	location = {Hong Kong},
	title = {Ellis: Dynamically Scaling Distributed Dataflows to Meet Runtime Targets},
	isbn = {978-1-5386-0692-6},
	url = {http://ieeexplore.ieee.org/document/8241102/},
	doi = {10.1109/CloudCom.2017.37},
	shorttitle = {Ellis},
	abstract = {Distributed dataﬂow systems like {MapReduce}, Spark, and Flink help users in analyzing large datasets with a set of cluster resources. Performance modeling and runtime prediction is then used for automatically allocating resources for speciﬁc performance goals. However, the actual performance of distributed dataﬂow jobs can vary signiﬁcantly due to factors like interference with co-located workloads, varying degrees of data locality, and failures.},
	eventtitle = {2017 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	pages = {146--153},
	booktitle = {2017 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	publisher = {{IEEE}},
	author = {Thamsen, Lauritz and Verbitskiy, Ilya and Beilharz, Jossekin and Renner, Thomas and Polze, Andreas and Kao, Odej},
	urldate = {2024-02-09},
	date = {2017-12},
	langid = {english},
	file = {Thamsen et al. - 2017 - Ellis Dynamically Scaling Distributed Dataflows to Meet Runtime Targets.pdf:C\:\\Users\\Alex\\Zotero\\storage\\5S7EJNSS\\Thamsen et al. - 2017 - Ellis Dynamically Scaling Distributed Dataflows to Meet Runtime Targets.pdf:application/pdf},
}

@article{gandomi_designing_2020,
	title = {Designing a {MapReduce} performance model in distributed heterogeneous platforms based on benchmarking approach},
	volume = {76},
	issn = {0920-8542, 1573-0484},
	url = {http://link.springer.com/10.1007/s11227-020-03162-9},
	doi = {10.1007/s11227-020-03162-9},
	abstract = {{MapReduce} framework is an effective method for big data parallel processing. Enhancing the performance of {MapReduce} clusters, along with reducing their job execution time, is a fundamental challenge to this approach. In fact, one is faced with two challenges here: how to maximize the execution overlap between jobs and how to create an optimum job scheduling. Accordingly, one of the most critical challenges to achieving these goals is developing a precise model to estimate the job execution time due to the large number and high volume of the submitted jobs, limited consumable resources, and the need for proper Hadoop configuration. This paper presents a model based on {MapReduce} phases for predicting the execution time of jobs in a heterogeneous cluster. Moreover, a novel heuristic method is designed, which significantly reduces the makespan of the jobs. In this method, first by providing the job profiling tool, we obtain the execution details of the {MapReduce} phases through log analysis. Then, using machine learning methods and statistical analysis, we propose a relevant model to predict runtime. Finally, another tool called job submission and monitoring tool is used for calculating makespan. Different experiments were conducted on the benchmarks under identical conditions for all jobs. The results show that the average makespan speedup for the proposed method was higher than an unoptimized case.},
	pages = {7177--7203},
	number = {9},
	journaltitle = {The Journal of Supercomputing},
	shortjournal = {J Supercomput},
	author = {Gandomi, Abolfazl and Movaghar, Ali and Reshadi, Midia and Khademzadeh, Ahmad},
	urldate = {2024-02-09},
	date = {2020-09},
	langid = {english},
	file = {Gandomi et al. - 2020 - Designing a MapReduce performance model in distributed heterogeneous platforms based on benchmarking.pdf:C\:\\Users\\Alex\\Zotero\\storage\\BJKRDGUM\\Gandomi et al. - 2020 - Designing a MapReduce performance model in distributed heterogeneous platforms based on benchmarking.pdf:application/pdf},
}

@article{ahmed_parallelization_2021,
	title = {A parallelization model for performance characterization of Spark Big Data jobs on Hadoop clusters},
	volume = {8},
	issn = {2196-1115},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00499-7},
	doi = {10.1186/s40537-021-00499-7},
	abstract = {This article proposes a new parallel performance model for different workloads of Spark Big Data applications running on Hadoop clusters. The proposed model can predict the runtime for generic workloads as a function of the number of executors, without necessarily knowing how the algorithms were implemented. For a certain problem size, it is shown that a model based on serial boundaries for a 2D arrangement of executors can fit the empirical data for various workloads. The empirical data was obtained from a real Hadoop cluster, using Spark and {HiBench}. The workloads used in this work were included {WordCount}, {SVM}, Kmeans, {PageRank} and Graph (Nweight). A particular runtime pattern emerged when adding more executors to run a job. For some workloads, the runtime was longer with more executors added. This phenomenon is predicted with the new model of parallelisation. The resulting equation from the model explains certain performance patterns that do not fit Amdahl’s law predictions, nor Gustafson’s equation. The results show that the proposed model achieved the best fit with all workloads and most of the data sizes, using the R-squared metric for the accuracy of the fitting of empirical data. The proposed model has advantages over machine learning models due to its simplicity, requiring a smaller number of experiments to fit the data. This is very useful to practitioners in the area of Big Data because they can predict runtime of specific applications by analysing the logs. In this work, the model is limited to changes in the number of executors for a fixed problem size.},
	pages = {107},
	number = {1},
	journaltitle = {Journal of Big Data},
	shortjournal = {J Big Data},
	author = {Ahmed, N. and Barczak, Andre L. C. and Rashid, Mohammad A. and Susnjak, Teo},
	urldate = {2024-02-09},
	date = {2021-12},
	langid = {english},
	file = {Ahmed et al. - 2021 - A parallelization model for performance characterization of Spark Big Data jobs on Hadoop clusters.pdf:C\:\\Users\\Alex\\Zotero\\storage\\QW7VUDMR\\Ahmed et al. - 2021 - A parallelization model for performance characterization of Spark Big Data jobs on Hadoop clusters.pdf:application/pdf},
}

@article{kros_pertract_2019,
	title = {{PerTract}: Model Extraction and Specification of Big Data Systems for Performance Prediction by the Example of Apache Spark and Hadoop},
	volume = {3},
	issn = {2504-2289},
	url = {https://www.mdpi.com/2504-2289/3/3/47},
	doi = {10.3390/bdcc3030047},
	shorttitle = {{PerTract}},
	abstract = {Evaluating and predicting the performance of big data applications are required to efficiently size capacities and manage operations. Gaining profound insights into the system architecture, dependencies of components, resource demands, and configurations cause difficulties to engineers. To address these challenges, this paper presents an approach to automatically extract and transform system specifications to predict the performance of applications. It consists of three components. First, a system- and tool-agnostic domain-specific language ({DSL}) allows the modeling of performance-relevant factors of big data applications, computing resources, and data workload. Second, {DSL} instances are automatically extracted from monitored measurements of Apache Spark and Apache Hadoop (i.e., {YARN} and {HDFS}) systems. Third, these instances are transformed to modeland simulation-based performance evaluation tools to allow predictions. By adapting {DSL} instances, our approach enables engineers to predict the performance of applications for different scenarios such as changing data input and resources. We evaluate our approach by predicting the performance of linear regression and random forest applications of the {HiBench} benchmark suite. Simulation results of adjusted {DSL} instances compared to measurement results show accurate predictions errors below 15\% based upon averages for response times and resource utilization.},
	pages = {47},
	number = {3},
	journaltitle = {Big Data and Cognitive Computing},
	shortjournal = {{BDCC}},
	author = {Kroß, Johannes and Krcmar, Helmut},
	urldate = {2024-02-13},
	date = {2019-08-09},
	langid = {english},
	file = {Kroß und Krcmar - 2019 - PerTract Model Extraction and Specification of Big Data Systems for Performance Prediction by the E.pdf:C\:\\Users\\Alex\\Zotero\\storage\\CYVDCHAN\\Kroß und Krcmar - 2019 - PerTract Model Extraction and Specification of Big Data Systems for Performance Prediction by the E.pdf:application/pdf},
}

@inproceedings{will_towards_2020,
	location = {Atlanta, {GA}, {USA}},
	title = {Towards Collaborative Optimization of Cluster Configurations for Distributed Dataflow Jobs},
	isbn = {978-1-72816-251-5},
	url = {https://ieeexplore.ieee.org/document/9377994/},
	doi = {10.1109/BigData50022.2020.9377994},
	abstract = {Analyzing large datasets with distributed dataﬂow systems requires the use of clusters. Public cloud providers offer a large variety and quantity of resources that can be used for such clusters. However, picking the appropriate resources in both type and number can often be challenging, as the selected conﬁguration needs to match a distributed dataﬂow job’s resource demands and access patterns. A good cluster conﬁguration avoids hardware bottlenecks and maximizes resource utilization, avoiding costly overprovisioning.},
	eventtitle = {2020 {IEEE} International Conference on Big Data (Big Data)},
	pages = {2851--2856},
	booktitle = {2020 {IEEE} International Conference on Big Data (Big Data)},
	publisher = {{IEEE}},
	author = {Will, Jonathan and Bader, Jonathan and Thamsen, Lauritz},
	urldate = {2024-02-14},
	date = {2020-12-10},
	langid = {english},
	file = {Will et al. - 2020 - Towards Collaborative Optimization of Cluster Configurations for Distributed Dataflow Jobs.pdf:C\:\\Users\\Alex\\Zotero\\storage\\6VHC3ZRG\\Will et al. - 2020 - Towards Collaborative Optimization of Cluster Configurations for Distributed Dataflow Jobs.pdf:application/pdf},
}

@inproceedings{scheinert_enel_2021,
	title = {Enel: Context-Aware Dynamic Scaling of Distributed Dataflow Jobs using Graph Propagation},
	url = {http://arxiv.org/abs/2108.12211},
	doi = {10.1109/IPCCC51483.2021.9679361},
	shorttitle = {Enel},
	abstract = {Distributed dataﬂow systems like Spark and Flink enable the use of clusters for scalable data analytics. While runtime prediction models can be used to initially select appropriate cluster resources given target runtimes, the actual runtime performance of dataﬂow jobs depends on several factors and varies over time. Yet, in many situations, dynamic scaling can be used to meet formulated runtime targets despite signiﬁcant performance variance.},
	pages = {1--8},
	booktitle = {2021 {IEEE} International Performance, Computing, and Communications Conference ({IPCCC})},
	author = {Scheinert, Dominik and Zhu, Houkun and Thamsen, Lauritz and Geldenhuys, Morgan K. and Will, Jonathan and Acker, Alexander and Kao, Odej},
	urldate = {2024-02-14},
	date = {2021-10-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2108.12211 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning},
	file = {Scheinert et al. - 2021 - Enel Context-Aware Dynamic Scaling of Distributed Dataflow Jobs using Graph Propagation.pdf:C\:\\Users\\Alex\\Zotero\\storage\\GCMEIGE2\\Scheinert et al. - 2021 - Enel Context-Aware Dynamic Scaling of Distributed Dataflow Jobs using Graph Propagation.pdf:application/pdf},
}

@collection{wang_advances_2016,
	location = {Cham},
	title = {Advances in Services Computing: 10th Asia-Pacific Services Computing Conference, {APSCC} 2016, Zhangjiajie, China, November 16-18, 2016, Proceedings},
	volume = {10065},
	isbn = {978-3-319-49177-6 978-3-319-49178-3},
	url = {http://link.springer.com/10.1007/978-3-319-49178-3},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Advances in Services Computing},
	publisher = {Springer International Publishing},
	editor = {Wang, Guojun and Han, Yanbo and Martínez Pérez, Gregorio},
	urldate = {2024-02-21},
	date = {2016},
	langid = {english},
	doi = {10.1007/978-3-319-49178-3},
	file = {Wang et al. - 2016 - Advances in Services Computing 10th Asia-Pacific Services Computing Conference, APSCC 2016, Zhangji.pdf:C\:\\Users\\Alex\\Zotero\\storage\\ZG3C73AK\\Wang et al. - 2016 - Advances in Services Computing 10th Asia-Pacific Services Computing Conference, APSCC 2016, Zhangji.pdf:application/pdf},
}

@article{myung_performance_2020,
	title = {Performance Prediction for Convolutional Neural Network on Spark Cluster},
	volume = {9},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/9/9/1340},
	doi = {10.3390/electronics9091340},
	abstract = {Applications with large-scale data are processed on a distributed system, such as Spark, as they are data- and computation-intensive. Predicting the performance of such applications is diﬃcult, because they are inﬂuenced by various aspects of conﬁgurations from the distributed framework level to the application level. In this paper, we propose a completion time prediction model based on machine learning for the representative deep learning model convolutional neural network ({CNN}) by analyzing the eﬀects of data, task, and resource characteristics on performance when executing the model in Spark cluster. To reduce the time utilized in collecting the data for training the model, we consider the causal relationship between the model features and the completion time based on Spark {CNN}’s distributed data-parallel model. The model features include the conﬁgurations of the Data Center {OS} Mesos environment, conﬁgurations of Apache Spark, and conﬁgurations of the {CNN} model. By applying the proposed model to famous {CNN} implementations, we achieved 99.98\% prediction accuracy about estimating the job completion time. In addition to the downscale search area for the model features, we leverage extrapolation, which signiﬁcantly reduces the model build time at most to 89\% with even better prediction accuracy in comparison to the actual work.},
	pages = {1340},
	number = {9},
	journaltitle = {Electronics},
	shortjournal = {Electronics},
	author = {Myung, Rohyoung and Yu, Heonchang},
	urldate = {2024-02-21},
	date = {2020-08-19},
	langid = {english},
	file = {Myung und Yu - 2020 - Performance Prediction for Convolutional Neural Network on Spark Cluster.pdf:C\:\\Users\\Alex\\Zotero\\storage\\H9AFADTF\\Myung und Yu - 2020 - Performance Prediction for Convolutional Neural Network on Spark Cluster.pdf:application/pdf},
}

@inproceedings{wang_mapreduce_2018,
	location = {New York, {NY}, {USA}},
	title = {On {MapReduce} Scheduling in Hadoop Yarn on Heterogeneous Clusters},
	isbn = {978-1-5386-4388-4},
	url = {https://ieeexplore.ieee.org/document/8456132/},
	doi = {10.1109/TrustCom/BigDataSE.2018.00264},
	abstract = {Hadoop is a distributed computing system widely used for big data processing in various domains. As the data volume continues to increase rapidly, Hadoop systems have become a critical contributor to the success of many big data applications. The {MapReduce} scheduler is a key component that determines the overall performance of a Hadoop cluster. In this paper, we formulate and investigate a task scheduling problem in a heterogeneous Hadoop cluster to minimize the completion time of a batch of {MapReduce} jobs. We ﬁrst design a prediction model to predict the end time of a task, which is used for placing the corresponding data block on a node in advance to reduce the data transmission time and the overall job completion time. Based on this prediction model, we propose a task matchingbased scheduling algorithm, referred to as {TMSA}, to schedule the tasks in the task queue in Hadoop, by taking into account the real-time performance of each node in the cluster and the matching degree between nodes and tasks. Experimental results show that the prediction model achieves high accuracy and {TMSA} signiﬁcantly reduces the completion time of a batch of {MapReduce} jobs compared to existing schedulers.},
	eventtitle = {2018 17th {IEEE} International Conference On Trust, Security And Privacy In Computing And Communications/ 12th {IEEE} International Conference On Big Data Science And Engineering ({TrustCom}/{BigDataSE})},
	pages = {1747--1754},
	booktitle = {2018 17th {IEEE} International Conference On Trust, Security And Privacy In Computing And Communications/ 12th {IEEE} International Conference On Big Data Science And Engineering ({TrustCom}/{BigDataSE})},
	publisher = {{IEEE}},
	author = {Wang, Meng and Wu, Chase Q. and Cao, Huiyan and Liu, Yang and Wang, Yongqiang and Hou, Aiqin},
	urldate = {2024-02-21},
	date = {2018-08},
	langid = {english},
	file = {Wang et al. - 2018 - On MapReduce Scheduling in Hadoop Yarn on Heterogeneous Clusters.pdf:C\:\\Users\\Alex\\Zotero\\storage\\I2BL8ERZ\\Wang et al. - 2018 - On MapReduce Scheduling in Hadoop Yarn on Heterogeneous Clusters.pdf:application/pdf},
}

@inproceedings{yeh_bigexplorer_2016,
	location = {Hsinchu, Taiwan},
	title = {{BigExplorer}: A configuration recommendation system for big data platform},
	isbn = {978-1-5090-5732-0},
	url = {http://ieeexplore.ieee.org/document/7880179/},
	doi = {10.1109/TAAI.2016.7880179},
	shorttitle = {{BigExplorer}},
	abstract = {With the complexity big data platform architectures, data engineer provides the infrastructure with computation and storage resource for data scientist and data analyst. With those supports, data scientists can focus their domain problem and design the intelligence module (e.g., prepare the data, select/train/tune the machine learning modules and validate the result). However, there is still a gap between system engineer team and data scientists/engineers team. For system engineers, they don’t have any knowledge about the application domain and the propose of the analytic program. For data scientists/engineers, they don’t know the configuration of the computation system, file system and database. Some application performance issues are related with system configurations. Data scientist and data engineer do not have information and knowledge about the system properties. In this paper, we propose a configuration layer with the current big data platform (i.e., Hadoop) and build a configuration recommendation system to collect data, pre-process data. Based on the processed data, we use semi-automatic feature engineer to provide features for data engineers and build the performance model with three different machine learning algorithms (i.e., random forest, gradient boosting machine and support vector regression). With the same two benchmarks (i.e., wordcount and terasort), our recommended configuration archives remarkable improvement than rule of thumb configuration and better than their improvements.},
	eventtitle = {2016 Conference on Technologies and Applications of Artificial Intelligence ({TAAI})},
	pages = {228--234},
	booktitle = {2016 Conference on Technologies and Applications of Artificial Intelligence ({TAAI})},
	publisher = {{IEEE}},
	author = {Yeh, Chao-Chun and Zhou, Jiazheng and Chang, Sheng-An and Lin, Xuan-Yi and Sun, Yichiao and Huang, Shih-Kun},
	urldate = {2024-02-21},
	date = {2016-11},
	langid = {english},
	file = {Yeh et al. - 2016 - BigExplorer A configuration recommendation system for big data platform.pdf:C\:\\Users\\Alex\\Zotero\\storage\\ZDWCBV6A\\Yeh et al. - 2016 - BigExplorer A configuration recommendation system for big data platform.pdf:application/pdf},
}

@article{li_marvelscaler_2022,
	title = {\textit{{MarVeLScaler}} : A Multi-View Learning-Based Auto-Scaling System for {MapReduce}},
	volume = {10},
	issn = {2168-7161, 2372-0018},
	url = {https://ieeexplore.ieee.org/document/8854222/},
	doi = {10.1109/TCC.2019.2944916},
	shorttitle = {\textit{{MarVeLScaler}}},
	abstract = {To promote cloud computing from current pay-per-request model to truly pay-per-use, tenants are crying for automatic tools to auto-estimate the amount of resources for {MapReduce} jobs. Such tools call for accurately quantifying the relationship among workload, resources and completion time. Various prediction models have been proposed. However, none of these models takes virtual machines’ ({VMs}) performance variance during a job’s execution into consideration, leading to underestimate the required resources and exceed the job’s deadline. To address this problem, we propose a multi-view deep learning model to capture real-time performance variance and automatically scale out the cloud cluster whenever necessary. We implement {MarVeLScaler}, a prototype system including two useful modules, namely, Scale Estimator and Scale Controller. Scale Estimator preliminarily estimates the required cluster size for a {MapReduce} job with given a concrete workload and deadline. During the runtime, Scale Controller adjusts the scale of the cluster according to its real-time running status to guarantee the job ﬁnished on time. We evaluate the performance of {MarVeLScaler} based on Hadoop in Alibaba Cloud. Experiments show that {MarVeLScaler} can provide 98.4 percent accuracy of prediction in determining initial cluster size, and save 30.8 percent of expense while still guaranteeing similar performance compared with the state-of-the-art methods.},
	pages = {506--520},
	number = {1},
	journaltitle = {{IEEE} Transactions on Cloud Computing},
	shortjournal = {{IEEE} Trans. Cloud Comput.},
	author = {Li, Yi and Liu, Fangming and Chen, Qiong and Sheng, Yibing and Zhao, Miao and Wang, Jianping},
	urldate = {2024-02-21},
	date = {2022-01-01},
	langid = {english},
	file = {Li et al. - 2022 - MarVeLScaler  A Multi-View Learning-Based Auto-Scaling System for MapReduce.pdf:C\:\\Users\\Alex\\Zotero\\storage\\RMT9BKVL\\Li et al. - 2022 - MarVeLScaler  A Multi-View Learning-Based Auto-Scaling System for MapReduce.pdf:application/pdf},
}

@inproceedings{chalvantzis_bbq_2017,
	location = {Madrid, Spain},
	title = {{BBQ}: Elastic {MapReduce} over Cloud Platforms},
	isbn = {978-1-5090-6611-7},
	url = {http://ieeexplore.ieee.org/document/7973777/},
	doi = {10.1109/CCGRID.2017.140},
	shorttitle = {{BBQ}},
	abstract = {Cloud infrastructure services such as Amazon {EMR} allow users to have access to tailor-made Big Data processing clusters within a few clicks from their web browser, thanks to the elastic property of the cloud. In virtual cloud environments, resource management is desired to be performed in a way which optimizes utilization, thus maximizing the value of the resources acquired. As cloud infrastructures become increasingly popular for Big Data analysis, the execution of programs with respect to user selected performance goals, such as job completion deadlines, remains a challenge. In this work we present {BARBECUE} ({joB} {AwaRe} Big-data Elasticity {CloUd} {managEment} System), a system that allows a Hadoop {MapReduce} virtual cluster to automatically adjust its size to the workload it is required to execute in order to respect individual jobs’ completion deadlines without acquiring more resources than the least necessary. To that end, {BBQ}’s Decision Making module uses a Performance Model for {MapReduce} jobs which can express cluster resources (i.e., {YARN} Container capacity) and execution time as a function of the number of nodes in the cluster. {BBQ} leverages the abstraction of {YARN}, making it feasible for integration with other execution frameworks, such as Spark, with the necessary changes to its pluggable Decision Making module. We also add a new feature to Hadoop {MapReduce} which can now dynamically, on-the-ﬂy update the number of selected {ReduceTasks} in cases where the cluster is expanded, so that our system makes full use of the resources it has acquired during the reduce phase of the execution. {BBQ} uses an adaptation of the hill climbing algorithm to estimate the optimal combination of number of nodes and reduce waves given a known job, its data input and an execution deadline. The attendees will be able to watch the system perform cluster resizes in real-time in order to execute its assigned jobs in time.},
	eventtitle = {2017 17th {IEEE}/{ACM} International Symposium on Cluster, Cloud and Grid Computing ({CCGRID})},
	pages = {766--771},
	booktitle = {2017 17th {IEEE}/{ACM} International Symposium on Cluster, Cloud and Grid Computing ({CCGRID})},
	publisher = {{IEEE}},
	author = {Chalvantzis, Nikolaos and Konstantinou, Ioannis and Kozyris, Nektarios},
	urldate = {2024-02-22},
	date = {2017-05},
	langid = {english},
	file = {Chalvantzis et al. - 2017 - BBQ Elastic MapReduce over Cloud Platforms.pdf:C\:\\Users\\Alex\\Zotero\\storage\\VKVZQAA8\\Chalvantzis et al. - 2017 - BBQ Elastic MapReduce over Cloud Platforms.pdf:application/pdf},
}

@article{peyravi_estimating_2020,
	title = {Estimating runtime of a job in Hadoop {MapReduce}},
	volume = {7},
	issn = {2196-1115},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00319-4},
	doi = {10.1186/s40537-020-00319-4},
	abstract = {Hadoop {MapReduce} is a framework to process vast amounts of data in the cluster of machines in a reliable and fault-tolerant manner. Since being aware of the runtime of a job is crucial to subsequent decisions of this platform and being better management, in this paper we propose a new method to estimate the runtime of a job. For this purpose, after analysis the anatomy of processing a job in Hadoop {MapReduce} precisely, we consider two cases: when a job runs for the first time or a job has run previously. In the first case, by considering essential and efficient parameters that higher impact on runtime we formulate each phase of the Hadoop execution pipeline and state them by mathematical expressions to calculate runtime of a job. In the second case, by referring to the profile or history of a job in the database and use a weighting system the runtime is estimated. The results show the average error rate is less than 12\% in the estimation of runtime for the first run and less than 8.5\% when the profile or history of the job has existed.},
	pages = {44},
	number = {1},
	journaltitle = {Journal of Big Data},
	shortjournal = {J Big Data},
	author = {Peyravi, Narges and Moeini, Ali},
	urldate = {2024-02-22},
	date = {2020-12},
	langid = {english},
	file = {Peyravi und Moeini - 2020 - Estimating runtime of a job in Hadoop MapReduce.pdf:C\:\\Users\\Alex\\Zotero\\storage\\W2VLVJ2B\\Peyravi und Moeini - 2020 - Estimating runtime of a job in Hadoop MapReduce.pdf:application/pdf},
}

@collection{nepal_big_2020,
	location = {Cham},
	title = {Big Data – {BigData} 2020: 9th International Conference, Held as Part of the Services Conference Federation, {SCF} 2020, Honolulu, {HI}, {USA}, September 18-20, 2020, Proceedings},
	volume = {12402},
	isbn = {978-3-030-59611-8 978-3-030-59612-5},
	url = {http://link.springer.com/10.1007/978-3-030-59612-5},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Big Data – {BigData} 2020},
	publisher = {Springer International Publishing},
	editor = {Nepal, Surya and Cao, Wenqi and Nasridinov, Aziz and Bhuiyan, Md Zakirul Alam and Guo, Xuan and Zhang, Liang-Jie},
	urldate = {2024-02-22},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-59612-5},
	file = {978-3-030-59612-5 (1).pdf:C\:\\Users\\Alex\\Zotero\\storage\\M8BQF7SK\\978-3-030-59612-5 (1).pdf:application/pdf},
}

@article{li_sparks_2018,
	title = {Spark’s operation time predictive in cloud computing environment based on {SRC}-{WSVR}},
	volume = {24},
	issn = {18758940, 09266801},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JHS-170580},
	doi = {10.3233/JHS-170580},
	abstract = {In Apache Spark cloud computing environment, computation capability of each node varies, together with the data size and uncertainties in application execution, these result in the differences in task execution time of a job. In order to enhance the accuracy in load execution time prediction, and reasonably guide the user to apply for Spark cluster resources, this paper researches on the execution ﬂow of Spark job, collects the load time consumption index, and puts forward the time index fusion calculation scheme. And then, this paper researches on the multiple linear regression model and support vector machine model to explore the payload execution time and {CPU} Core, inputting data volume, memory size and other performance indicators. Based on the two models above, this paper proposes a Standard Regression Coefﬁcient-based Weighted Support Vector Regression time prediction model ({SRC}-{WSVR}). Finally, through comparing the results from the prediction model proposed in this paper with conventional regression prediction model and Standard Support Vector Machine model, it proves that {SRC}-{WSVR} has a higher prediction accuracy, which can provide valid data reference for predicting Spark resource consumption.},
	pages = {49--62},
	number = {1},
	journaltitle = {Journal of High Speed Networks},
	shortjournal = {{JHS}},
	author = {Li, Peng and Dong, Lu and Xu, He and Lau, Ting Fung},
	urldate = {2024-02-22},
	date = {2018-01-15},
	langid = {english},
	file = {Li et al. - 2018 - Spark’s operation time predictive in cloud computing environment based on SRC-WSVR.pdf:C\:\\Users\\Alex\\Zotero\\storage\\TGXRKC5L\\Li et al. - 2018 - Spark’s operation time predictive in cloud computing environment based on SRC-WSVR.pdf:application/pdf},
}

@article{aseman-manzar_cost-aware_2022,
	title = {Cost-aware Resource Recommendation for {DAG}-based Big Data Workflows: An Apache Spark Case Study},
	issn = {1939-1374, 2372-0204},
	url = {https://ieeexplore.ieee.org/document/9894699/},
	doi = {10.1109/TSC.2022.3203010},
	shorttitle = {Cost-aware Resource Recommendation for {DAG}-based Big Data Workflows},
	abstract = {The era of personal resources being sufﬁcient for enterprise big data computations has passed. As computations are executed in the cloud, small policy changes of cloud operators may cause considerable changes in operational costs. Carefully choosing the amount of resources for a given application is thus of great importance. This, however, requires a priori knowledge of the application’s performance under different conﬁgurations. Creating a performance prediction model needs to account for the heterogeneity of resources and the diversity in application workﬂows. Previous approaches for heterogeneous environments consider a black-box representation of the application which results in single-purpose models. This paper addresses the problem with two graybox prediction models using linear programming ({LP}) and mixed-integer linear programming ({MILP}). Given a set of available resources, the models consider Apache Spark applications and their Directed Acyclic Graph ({DAG}) of workﬂow running on top of a Hadoop-{YARN} cluster. We then propose a conﬁguration recommendation algorithm to optimize the cost-performance trade-offs when renting machine instances. The accuracy of the proposed models is evaluated with real-world executions of several representative applications on the Wikipedia dataset and the {TPC}-{DS} benchmark. The average error of only 3.28\% for the proposed prediction models demonstrates the practicality of the proposed approach in handling cost-performance trade-offs.},
	pages = {1--12},
	journaltitle = {{IEEE} Transactions on Services Computing},
	shortjournal = {{IEEE} Trans. Serv. Comput.},
	author = {Aseman-Manzar, Mohammad-Mohsen and Karimian-Aliabadi, Soroush and Entezari-Maleki, Reza and Egger, Bernhard and Movaghar, Ali},
	urldate = {2024-02-23},
	date = {2022},
	langid = {english},
	file = {Aseman-Manzar et al. - 2022 - Cost-aware Resource Recommendation for DAG-based Big Data Workflows An Apache Spark Case Study.pdf:C\:\\Users\\Alex\\Zotero\\storage\\PFMTSMSQ\\Aseman-Manzar et al. - 2022 - Cost-aware Resource Recommendation for DAG-based Big Data Workflows An Apache Spark Case Study.pdf:application/pdf},
}

@inproceedings{xu_ispot_2017,
	location = {Guangzhou},
	title = {{iSpot}: Achieving Predictable Performance for Big Data Analytics with Cloud Transient Servers},
	isbn = {978-1-5386-3790-6},
	url = {https://ieeexplore.ieee.org/document/8367282/},
	doi = {10.1109/ISPA/IUCC.2017.00052},
	shorttitle = {{iSpot}},
	abstract = {Achieving predictable performance for big data analytics running on cloud transient servers (e.g., {EC}2 spot instances) is challenging, because the transient server can be revoked by the cloud and the spot price is nontrivial to predict. Undoubtedly, choosing the low-price yet unstable cloud resources can severely degrade the job performance. To tackle this issue, this paper proposes {iSpot}, a cost-efﬁcient spot instance provisioning framework in the cloud, by focusing on Spark as a representative {DAG} (Directed Acyclic Graph)-style big analytics workload. Speciﬁcally, it identiﬁes the availability zones with stable spot instance resources by devising an accurate {LSTM} (Long Short-Term Memory)-based price prediction method. {iSpot} further predicts the performance of Spark stages and jobs by designing a ﬁned-grained performance model using the job proﬁling and the {DAG} information of stages. Based on the price prediction and Spark performance model, {iSpot} is able to provision the spot instances with the cost-efﬁcient instance type (i.e., the instance type that achieves the minimum monetary cost), in order to deliver predictable performance for big data analytics. Extensive prototype experiments on Amazon {EC}2 demonstrate that {iSpot} can guarantee the performance of big data analytics while reducing the job budget with cloud transient servers.},
	eventtitle = {2017 {IEEE} International Symposium on Parallel and Distributed Processing with Applications and 2017 {IEEE} International Conference on Ubiquitous Computing and Communications ({ISPA}/{IUCC})},
	pages = {314--321},
	booktitle = {2017 {IEEE} International Symposium on Parallel and Distributed Processing with Applications and 2017 {IEEE} International Conference on Ubiquitous Computing and Communications ({ISPA}/{IUCC})},
	publisher = {{IEEE}},
	author = {Xu, Fei and Jiang, Huan and Zheng, Haoyue and Shao, Wujie},
	urldate = {2024-02-23},
	date = {2017-12},
	langid = {english},
	file = {Xu et al. - 2017 - iSpot Achieving Predictable Performance for Big Data Analytics with Cloud Transient Servers.pdf:C\:\\Users\\Alex\\Zotero\\storage\\ZNXSFW9I\\Xu et al. - 2017 - iSpot Achieving Predictable Performance for Big Data Analytics with Cloud Transient Servers.pdf:application/pdf},
}

@inproceedings{sewal_machine_2022,
	location = {Solan, Himachal Pradesh, India},
	title = {A Machine Learning Approach for Predicting Execution Statistics of Spark Application},
	isbn = {978-1-66545-400-1 978-1-66545-401-8},
	url = {https://ieeexplore.ieee.org/document/10053356/},
	doi = {10.1109/PDGC56933.2022.10053356},
	abstract = {Apache Spark is one of the most popular, widely used and open-source distributed processing framework that can process huge site datasets in time efficient manner due to its in-memory computational capabilities. However, there are several factors that can affect the performance of an application which include the nature and size of the input dataset, computational capability of the system and nature and design of the algorithm. Hence, there are different parameters that are required to correctly predict the execution statistics of a Spark application which include execution time of jobs, stages and tasks, memory requirement and usage at the execution level and I/O cost in the form of read/ write shuffling of data. To address these challenges, a simulation and machine learning based prediction model is presented in this paper that takes only a few initial samples of execution statistics and predicts the performance and execution statistics of the Spark application with high accuracy. The proposed model is evaluated on the Wordcount application and Spark standalone mode and accuracy metrics show that the proposed model achieves high accuracy in predicting execution statistics.},
	eventtitle = {2022 Seventh International Conference on Parallel, Distributed and Grid Computing ({PDGC})},
	pages = {331--336},
	booktitle = {2022 Seventh International Conference on Parallel, Distributed and Grid Computing ({PDGC})},
	publisher = {{IEEE}},
	author = {Sewal, Piyush and Singh, Hari},
	urldate = {2024-02-23},
	date = {2022-11-25},
	langid = {english},
	file = {Sewal und Singh - 2022 - A Machine Learning Approach for Predicting Execution Statistics of Spark Application.pdf:C\:\\Users\\Alex\\Zotero\\storage\\TNVSVHG8\\Sewal und Singh - 2022 - A Machine Learning Approach for Predicting Execution Statistics of Spark Application.pdf:application/pdf},
}

@article{karimian-aliabadi_fixed-point_2023,
	title = {Fixed-Point Iteration Approach to Spark Scalable Performance Modeling and Evaluation},
	volume = {11},
	issn = {2168-7161, 2372-0018},
	url = {https://ieeexplore.ieee.org/document/9573291/},
	doi = {10.1109/TCC.2021.3119943},
	abstract = {Companies depend on mining data to grow their business more than ever. To achieve optimal performance of Big Data analytics workloads, a careful conﬁguration of the cluster and the employed software framework is required. The lack of ﬂexible and accurate performance models, however, render this a challenging task. This article ﬁlls this gap by presenting accurate performance prediction models based on Stochastic Activity Networks ({SANs}). In contrast to existing work, the presented models consider multiple work queues, a critical feature to achieve high accuracy in realistic usage scenarios. We ﬁrst introduce a monolithic analytical model for a multi-queue {YARN} cluster running {DAG}-based Big Data applications that models each queue individually. To overcome the limited scalability of the monolithic model, we then present a ﬁxed-point model that iteratively computes the throughput of a single queue with respect to the rest of the system until a ﬁxed-point is reached. The models are evaluated on a real-world cluster running the widelyused Apache Spark framework and the {YARN} scheduler. Experiments with the common transaction-based {TPC}-{DS} benchmark show that the proposed models achieve an average error of only 5:6\% in predicting the execution time of the Spark jobs. The presented models enable businesses to optimize their cluster conﬁguration for a given workload and thus to reduce their expenses and minimize service level agreement ({SLA}) violations. Makespan minimization and per-stage analysis are examined as representative efforts to further assess the applicability of our proposition.},
	pages = {897--910},
	number = {1},
	journaltitle = {{IEEE} Transactions on Cloud Computing},
	shortjournal = {{IEEE} Trans. Cloud Comput.},
	author = {Karimian-Aliabadi, Soroush and Aseman-Manzar, Mohammad-Mohsen and Entezari-Maleki, Reza and Ardagna, Danilo and Egger, Bernhard and Movaghar, Ali},
	urldate = {2024-02-23},
	date = {2023-01-01},
	langid = {english},
	file = {Karimian-Aliabadi et al. - 2023 - Fixed-Point Iteration Approach to Spark Scalable Performance Modeling and Evaluation.pdf:C\:\\Users\\Alex\\Zotero\\storage\\AUUAPAJ3\\Karimian-Aliabadi et al. - 2023 - Fixed-Point Iteration Approach to Spark Scalable Performance Modeling and Evaluation.pdf:application/pdf},
}

@inproceedings{shao_collaborative_2017,
	location = {Wellington, New Zealand},
	title = {A collaborative filtering based approach to performance prediction for parallel applications},
	isbn = {978-1-5090-6199-0},
	url = {http://ieeexplore.ieee.org/document/8066716/},
	doi = {10.1109/CSCWD.2017.8066716},
	abstract = {Parallel application jobs account for a large population in current domain of cloud computing and Big Data processing services, whose execution time can be varied greatly with different runtime conﬁgurations. For efﬁciently scheduling resources and services to run parallel jobs, the ability to quickly and accurately estimate the performance of parallel applications is critical. Analytic predictive models based on traditional modeling techniques such as queuing systems are difﬁcult to construct for parallel applications, due to the high complexity lying in the structures of parallel application models. Furthermore, due to the heterogeneity of resources computing capacities with a scalable computing environment such as a cloud computing platform, performance analytic and prediction becomes increasingly difﬁcult for parallel applications. To address this problem, in this paper we propose a collaborative ﬁltering based approach to quickly and accurately predict the execution time of parallel applications running in heterogenous resources. Particularly, we use the widely used Apache Spark platform as the running framework for parallel applications, and propose a bounds-based performance model to improve the prediction accuracy. Through extensive simulations and experiments on real Spark clusters and two large-scale machine learning applications as well as the simple but classic {WordCount} sample application, we show that the proposed Collaborative Filtering based approach and bounds-based performance model can accurately estimate the performance of parallel applications.},
	eventtitle = {2017 {IEEE} 21st International Conference on Computer Supported Cooperative Work in Design ({CSCWD})},
	pages = {331--336},
	booktitle = {2017 {IEEE} 21st International Conference on Computer Supported Cooperative Work in Design ({CSCWD})},
	publisher = {{IEEE}},
	author = {Shao, Qingshi and Pan, Li and Liu, Shijun and Liu, Xinyan},
	urldate = {2024-02-23},
	date = {2017-04},
	langid = {english},
	file = {Shao et al. - 2017 - A collaborative filtering based approach to performance prediction for parallel applications.pdf:C\:\\Users\\Alex\\Zotero\\storage\\VX7K9FEU\\Shao et al. - 2017 - A collaborative filtering based approach to performance prediction for parallel applications.pdf:application/pdf},
}

@inproceedings{li_cross-domain_2020,
	location = {Oxford, United Kingdom},
	title = {Cross-Domain Workloads Performance Prediction via Runtime Metrics Transferring},
	isbn = {978-1-72816-981-1},
	url = {https://ieeexplore.ieee.org/document/9183580/},
	doi = {10.1109/JCC49151.2020.00015},
	abstract = {Modern cloud vendors provide thousands of types of virtual machines, presenting the user a bewildering choice. Many previous works try to train accurate models for a workload to predict its performance on a given conﬁguration, which could be applicable to a concrete class of workloads (e.g., Spark-{SVM} jobs). But it is difﬁcult to build a universal prediction model for all the workloads, mostly because different workloads have different runtime metrics distribution. We argue that if the runtime metrics data could be transferred before being fed to the prediction model, the knowledge learned in one workload may be reused to other workloads. In this paper, we synthetically investigate the similarity and difference between a set of workloads and the possibility to transfer between them. We use an {LSTM} auto-encoder to encode the temporal runtime metrics into a ﬁxed-size vector, which is fed into a linear regression model. In our experiments, the metrics transferring approach could help reduce the prediction error of the linear regression model.},
	eventtitle = {2020 {IEEE} International Conference on Joint Cloud Computing ({JCC})},
	pages = {38--42},
	booktitle = {2020 {IEEE} International Conference on Joint Cloud Computing},
	publisher = {{IEEE}},
	author = {Li, Yan and Ma, Junming and Cao, Donggang},
	urldate = {2024-02-26},
	date = {2020-08},
	langid = {english},
	file = {Li et al. - 2020 - Cross-Domain Workloads Performance Prediction via Runtime Metrics Transferring.pdf:C\:\\Users\\Alex\\Zotero\\storage\\ZWY9S9J3\\Li et al. - 2020 - Cross-Domain Workloads Performance Prediction via Runtime Metrics Transferring.pdf:application/pdf},
}

@inproceedings{maroulis_fast_2019,
	location = {Valencia, Spain},
	title = {Fast. Efficient Performance Predictions for Big Data Applications},
	isbn = {978-1-72810-151-4},
	url = {https://ieeexplore.ieee.org/document/8759325/},
	doi = {10.1109/ISORC.2019.00034},
	abstract = {In recent years we observe a rapid growth in the deployment of machine learning workloads on big data analytics frameworks like Apache Spark and Apache Flink. These workloads are typically represented as graphs, run on shared infrastructures and often have much more demanding resource requirements than those traditionally found in typical enterprise settings. However, predicting the execution times of the workloads is important as they often run on shared public or private infrastructures and, thus, their execution is greatly affected by the resource sharing, the hardware infrastructure utilized as well as the choice of the conﬁguration parameters provided by the frameworks.},
	eventtitle = {2019 {IEEE} 22nd International Symposium on Real-Time Distributed Computing ({ISORC})},
	pages = {126--133},
	booktitle = {2019 {IEEE} 22nd International Symposium on Real-Time Distributed Computing ({ISORC})},
	publisher = {{IEEE}},
	author = {Maroulis, Stathis and Zacheilas, Nikos and Theocharis, Thanasis and Kalogeraki, Vana},
	urldate = {2024-02-26},
	date = {2019-05},
	langid = {english},
	file = {Maroulis et al. - 2019 - Fast. Efficient Performance Predictions for Big Data Applications.pdf:C\:\\Users\\Alex\\Zotero\\storage\\N48XQ5HF\\Maroulis et al. - 2019 - Fast. Efficient Performance Predictions for Big Data Applications.pdf:application/pdf},
}

@article{jie_performance_2022,
	title = {A performance modeling-based {HADOOP} configuration tuning strategy},
	volume = {7},
	issn = {2365-6379, 2365-6387},
	url = {https://link.springer.com/10.1007/s41204-021-00184-3},
	doi = {10.1007/s41204-021-00184-3},
	abstract = {Hadoop that is a distributed system infrastructure provides a stable and reliable set of interfaces for applications. This paper proposes a Hadoop configuration parameter tuning method H-Tune, it is based on integrated learning modeling and meta-heuristic optimization. The experimental results show that the performance model can accurately predict the running time of {MapReduce} applications. After tuning with the Hadoop configuration parameter method proposed in this paper, the average acceleration ratio is 9.6 times and 1.5 times, respectively, and the performance of {MapReduce} application has been significantly improved.},
	pages = {725--736},
	number = {3},
	journaltitle = {Nanotechnology for Environmental Engineering},
	shortjournal = {Nanotechnol. Environ. Eng.},
	author = {Jie, Huang},
	urldate = {2024-02-26},
	date = {2022-09},
	langid = {english},
	file = {Jie - 2022 - A performance modeling-based HADOOP configuration tuning strategy.pdf:C\:\\Users\\Alex\\Zotero\\storage\\KR52X5HT\\Jie - 2022 - A performance modeling-based HADOOP configuration tuning strategy.pdf:application/pdf},
}

@inproceedings{ye_performance_2017,
	location = {Shenzhen, China},
	title = {Performance Tuning and Modeling for Big Data Applications in Docker Containers},
	isbn = {978-1-5386-3486-8},
	url = {http://ieeexplore.ieee.org/document/8026871/},
	doi = {10.1109/NAS.2017.8026871},
	abstract = {Docker container is experiencing a rapid development with the support from industry and being widely used in large scale production cloud environment, due to the beneﬁts of speedy launching time and tiny memory footprint. However the performance of big data applications (e.g., Spark) running in Docker containers is still not clear due to the complex parameter conﬁguration and interference between neighbor containers.},
	eventtitle = {2017 International Conference on Networking, Architecture, and Storage ({NAS})},
	pages = {1--6},
	booktitle = {2017 International Conference on Networking, Architecture, and Storage ({NAS})},
	publisher = {{IEEE}},
	author = {Ye, Kejiang and Ji, Yunjie},
	urldate = {2024-02-26},
	date = {2017-08},
	langid = {english},
	file = {Ye und Ji - 2017 - Performance Tuning and Modeling for Big Data Applications in Docker Containers.pdf:C\:\\Users\\Alex\\Zotero\\storage\\D8F2XZ7B\\Ye und Ji - 2017 - Performance Tuning and Modeling for Big Data Applications in Docker Containers.pdf:application/pdf},
}

@article{li_phronesis_2022,
	title = {Phronesis: Efficient Performance Modeling for High-dimensional Configuration Tuning},
	volume = {19},
	issn = {1544-3566, 1544-3973},
	url = {https://dl.acm.org/doi/10.1145/3546868},
	doi = {10.1145/3546868},
	shorttitle = {Phronesis},
	abstract = {We present Phronesis, a learning framework for efficiently modeling the performance of data analytic workloads as a function of their high-dimensional software configuration parameters. Accurate performance models are useful for efficiently optimizing data analytic performance. Phronesis explicitly considers the error decomposition in statistical learning and implications for efficient data acquisition and model growth strategies in performance modeling. We demonstrate Phronesis with three popular machine learning models commonly used in performance tuning: neural network, random forest, and regression spline. We implement and evaluate it for Spark configuration parameters. We show that Phronesis significantly reduces data collection time for training predictive models by up to 57\% and 37\%, on average, compared to state-of-the-art techniques in building Spark performance models. Furthermore, we construct a configuration autotuning pipeline based on Phronesis. Our results indicate up to 30\% gains in performance for Spark workloads over previous, state-of-the-art tuning strategies that use high-dimensional models.},
	pages = {1--26},
	number = {4},
	journaltitle = {{ACM} Transactions on Architecture and Code Optimization},
	shortjournal = {{ACM} Trans. Archit. Code Optim.},
	author = {Li, Yuhao and Lee, Benjamin C.},
	urldate = {2024-02-26},
	date = {2022-12-31},
	langid = {english},
	file = {Li und Lee - 2022 - Phronesis Efficient Performance Modeling for High-dimensional Configuration Tuning.pdf:C\:\\Users\\Alex\\Zotero\\storage\\EQ3PXHSB\\Li und Lee - 2022 - Phronesis Efficient Performance Modeling for High-dimensional Configuration Tuning.pdf:application/pdf},
}

@article{shen_novel_2023,
	title = {A Novel Multi-Task Performance Prediction Model for Spark},
	volume = {13},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/13/22/12242},
	doi = {10.3390/app132212242},
	abstract = {Performance prediction of Spark plays a vital role in cluster resource management and system efﬁciency improvement. The performance of Spark is affected by several variables, such as the size of the input data, the computational power of the system, and the complexity of the algorithm. At the same time, less research has focused on multi-task performance prediction models for Spark. To address these challenges, we propose a multi-task Spark performance prediction model. The model integrates a multi-head attention mechanism and a convolutional neural network. It implements the prediction of execution times for single or multiple Spark applications. Firstly, the data are dimensionally reduced by a dimensionality reduction algorithm and fed into the model. Secondly, the model integrates a multi-head attention mechanism and a convolutional neural network. It captures complex relationships between data features and uses these features for Spark performance prediction. Finally, we use residual connections to prevent overﬁtting. To validate the performance of the model, we conducted experiments on four Spark benchmark applications. Compared to the benchmark prediction model, our model obtains better performance metrics. In addition, our model predicts multiple Spark benchmark applications simultaneously and maintains deviations within permissible limits. It provides a novel way for the assessment and optimization of Spark.},
	pages = {12242},
	number = {22},
	journaltitle = {Applied Sciences},
	shortjournal = {Applied Sciences},
	author = {Shen, Chao and Chen, Chen and Rao, Guozheng},
	urldate = {2024-02-26},
	date = {2023-11-11},
	langid = {english},
	file = {Shen et al. - 2023 - A Novel Multi-Task Performance Prediction Model for Spark.pdf:C\:\\Users\\Alex\\Zotero\\storage\\936MSSB6\\Shen et al. - 2023 - A Novel Multi-Task Performance Prediction Model for Spark.pdf:application/pdf},
}

@misc{zaouk_neural-based_2021,
	title = {Neural-based Modeling for Performance Tuning of Spark Data Analytics},
	url = {http://arxiv.org/abs/2101.08167},
	abstract = {Cloud data analytics has become an integral part of enterprise business operations for data-driven insight discovery. Performance modeling of cloud data analytics is crucial for performance tuning and other critical operations in the cloud. Traditional modeling techniques fail to adapt to the high degree of diversity in workloads and system behaviors in this domain. In this paper, we bring recent Deep Learning techniques to bear on the process of automated performance modeling of cloud data analytics, with a focus on Spark data analytics as representative workloads. At the core of our work is the notion of learning workload embeddings (with a set of desired properties) to represent fundamental computational characteristics of diﬀerent jobs, which enable performance prediction when used together with job conﬁgurations that control resource allocation and other system knobs. Our work provides an in-depth study of diﬀerent modeling choices that suit our requirements. Results of extensive experiments reveal the strengths and limitations of diﬀerent modeling methods, as well as superior performance of our best performing method over a state-of-the-art modeling tool for cloud analytics.},
	number = {{arXiv}:2101.08167},
	publisher = {{arXiv}},
	author = {Zaouk, Khaled and Song, Fei and Lyu, Chenghao and Diao, Yanlei},
	urldate = {2024-02-28},
	date = {2021-01-20},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2101.08167 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Computer Science - Databases},
	file = {Zaouk et al. - 2021 - Neural-based Modeling for Performance Tuning of Spark Data Analytics.pdf:C\:\\Users\\Alex\\Zotero\\storage\\5IUD5Y59\\Zaouk et al. - 2021 - Neural-based Modeling for Performance Tuning of Spark Data Analytics.pdf:application/pdf},
}

@inproceedings{thamsen_selecting_2016,
	location = {Las Vegas, {NV}, {USA}},
	title = {Selecting resources for distributed dataflow systems according to runtime targets},
	isbn = {978-1-5090-5252-3},
	url = {http://ieeexplore.ieee.org/document/7820629/},
	doi = {10.1109/PCCC.2016.7820629},
	abstract = {Distributed dataﬂow systems like Spark or Flink enable users to analyze large datasets. Users create programs by providing sequential user-deﬁned functions for a set of welldeﬁned operations, select a set of resources, and the systems automatically distribute the jobs across these resources. However, selecting resources for speciﬁc performance needs is inherently difﬁcult and users consequently tend to overprovision, which results in poor cluster utilization. At the same time, many important jobs are executed recurringly in production clusters.},
	eventtitle = {2016 {IEEE} 35th International Performance Computing and Communications Conference ({IPCCC})},
	pages = {1--8},
	booktitle = {2016 {IEEE} 35th International Performance Computing and Communications Conference ({IPCCC})},
	publisher = {{IEEE}},
	author = {Thamsen, Lauritz and Verbitskiy, Ilya and Schmidt, Florian and Renner, Thomas and Kao, Odej},
	urldate = {2024-02-28},
	date = {2016-12},
	langid = {english},
	file = {Thamsen et al. - 2016 - Selecting resources for distributed dataflow systems according to runtime targets.pdf:C\:\\Users\\Alex\\Zotero\\storage\\BVSA5VJY\\Thamsen et al. - 2016 - Selecting resources for distributed dataflow systems according to runtime targets.pdf:application/pdf},
}

@article{myung_machine-learning_2021,
	title = {Machine-Learning Based Memory Prediction Model for Data Parallel Workloads in Apache Spark},
	volume = {13},
	issn = {2073-8994},
	url = {https://www.mdpi.com/2073-8994/13/4/697},
	doi = {10.3390/sym13040697},
	abstract = {A lack of memory can lead to job failures or increase processing times for garbage collection. However, if too much memory is provided, the processing time is only marginally reduced, and most of the memory is wasted. Many big data processing tasks are executed in cloud environments. When renting virtual resources in a cloud environment, it is necessary to pay the cost according to the speciﬁcations of resources (i.e., the number of virtual cores and the size of memory), as well as rental time. In this paper, given the type of workload and volume of the input data, we analyze the memory usage pattern and derive the efﬁcient memory size of data-parallel workloads in Apache Spark. Then, we propose a machine-learning-based prediction model that determines the efﬁcient memory for a given workload and data. To determine the validity of the proposed model, we applied it to data-parallel workloads which include a deep learning model. The predicted memory values were in close agreement with the actual amount of required memory. Additionally, the whole building time for the proposed model requires a maximum of 44\% of the total execution time of a data-parallel workload. The proposed model can improve memory efﬁciency up to 1.89 times compared with the vanilla Spark setting.},
	pages = {697},
	number = {4},
	journaltitle = {Symmetry},
	shortjournal = {Symmetry},
	author = {Myung, Rohyoung and Choi, Sukyong},
	urldate = {2024-02-29},
	date = {2021-04-16},
	langid = {english},
	file = {Myung und Choi - 2021 - Machine-Learning Based Memory Prediction Model for Data Parallel Workloads in Apache Spark.pdf:C\:\\Users\\Alex\\Zotero\\storage\\5ETXE5JG\\Myung und Choi - 2021 - Machine-Learning Based Memory Prediction Model for Data Parallel Workloads in Apache Spark.pdf:application/pdf},
}

@inproceedings{gu_auto-tuning_2018,
	location = {Kansas City, {MO}},
	title = {Auto-Tuning Spark Configurations Based on Neural Network},
	isbn = {978-1-5386-3180-5},
	url = {https://ieeexplore.ieee.org/document/8422658/},
	doi = {10.1109/ICC.2018.8422658},
	abstract = {For massive data processing platforms such as Spark, configuration tuning is a necessary step since it is closely related to task parallelism, resource allocation and fault tolerance, which has a great influence on performance. However, to tune more than 190 interrelated configuration parameters of Spark for performance optimization is a challenging job.},
	eventtitle = {2018 {IEEE} International Conference on Communications ({ICC} 2018)},
	pages = {1--6},
	booktitle = {2018 {IEEE} International Conference on Communications ({ICC})},
	publisher = {{IEEE}},
	author = {Gu, Jing and Li, Ying and Tang, Hongyan and Wu, Zhonghai},
	urldate = {2024-02-29},
	date = {2018-05},
	langid = {english},
	file = {Gu et al. - 2018 - Auto-Tuning Spark Configurations Based on Neural Network.pdf:C\:\\Users\\Alex\\Zotero\\storage\\K56GEPDW\\Gu et al. - 2018 - Auto-Tuning Spark Configurations Based on Neural Network.pdf:application/pdf},
}

@collection{wen_algorithms_2020,
	location = {Cham},
	title = {Algorithms and Architectures for Parallel Processing: 19th International Conference, {ICA}3PP 2019, Melbourne, {VIC}, Australia, December 9–11, 2019, Proceedings, Part {II}},
	volume = {11945},
	isbn = {978-3-030-38960-4 978-3-030-38961-1},
	url = {https://link.springer.com/10.1007/978-3-030-38961-1},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Algorithms and Architectures for Parallel Processing},
	publisher = {Springer International Publishing},
	editor = {Wen, Sheng and Zomaya, Albert and Yang, Laurence T.},
	urldate = {2024-02-29},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-38961-1},
	file = {Wen et al. - 2020 - Algorithms and Architectures for Parallel Processing 19th International Conference, ICA3PP 2019, Me.pdf:C\:\\Users\\Alex\\Zotero\\storage\\4YD6S4GI\\Wen et al. - 2020 - Algorithms and Architectures for Parallel Processing 19th International Conference, ICA3PP 2019, Me.pdf:application/pdf},
}

@inproceedings{ye_machine_2020,
	location = {Austin, {TX}, {USA}},
	title = {On Machine Learning-based Stage-aware Performance Prediction of Spark Applications},
	isbn = {978-1-72819-829-3},
	url = {https://ieeexplore.ieee.org/document/9391564/},
	doi = {10.1109/IPCCC50635.2020.9391564},
	abstract = {The data volume of large-scale applications in various science, engineering, and business domains has experienced an explosive growth over the past decade, and has gone far beyond the computing capability and storage capacity of any single server. As a viable solution, such data is oftentimes stored in distributed ﬁle systems and processed by parallel computing engines, as exempliﬁed by Spark, which has gained increasing popularity over the traditional {MapReduce} framework due to its fast in-memory processing of streaming data. Spark engines are generally deployed in cloud environments such as Amazon {EC}2 and Alibaba Cloud. However, storage and computing resources in these cloud environments are typically provisioned on a payas-you-go basis and thus an accurate estimate of the execution time of Spark workloads is critical to making full utilization of cloud resources and meeting performance requirements of end users. Our insight is that the execution pattern of many Spark workloads is qualitatively similar, which makes it possible to leverage historical performance data to predict the execution time of a given Spark application. We use the execution information extracted from Spark History Server as training data and develop a stage-aware hierarchical neural network model for performance prediction. Experimental results show that the proposed hierarchical model achieves higher accuracy than a holistic prediction model at the end-to-end level, and also outperforms other existing regression-based prediction methods.},
	eventtitle = {2020 {IEEE} 39th International Performance Computing and Communications Conference ({IPCCC})},
	pages = {1--8},
	booktitle = {2020 {IEEE} 39th International Performance Computing and Communications Conference ({IPCCC})},
	publisher = {{IEEE}},
	author = {Ye, Guangjun and Liu, Wuji and Wu, Chase Q. and Shen, Wei and Lyu, Xukang},
	urldate = {2024-02-29},
	date = {2020-11-06},
	langid = {english},
}

@article{ataie_hybrid_2022,
	title = {A Hybrid Machine Learning Approach for Performance Modeling of Cloud-Based Big Data Applications},
	volume = {65},
	issn = {0010-4620, 1460-2067},
	url = {https://academic.oup.com/comjnl/article/65/12/3123/6372951},
	doi = {10.1093/comjnl/bxab131},
	abstract = {Abstract
            Nowadays, Apache Hadoop and Apache Spark are two of the most prominent distributed solutions for processing big data applications on the market. Since in many cases these frameworks are adopted to support business critical activities, it is often important to predict with fair confidence the execution time of submitted applications, for instance when service-level agreements are established with end-users. In this work, we propose and validate a hybrid approach for the performance prediction of big data applications running on clouds, which exploits both analytical modeling and machine learning ({ML}) techniques and it is able to achieve a good accuracy without too many time consuming and costly experiments on a real setup. The experimental results show how the proposed approach attains improvement in accuracy, number of experiments to be run on the operational system and cost over applying {ML} techniques without any support from analytical models. Moreover, we compare our approach with Ernest, an {ML}-based technique proposed in the literature by the Spark inventors. Experiments show that Ernest can accurately estimate the performance in interpolating scenarios while it fails to predict the performance when configurations with increasing number of cores are considered. Finally, a comparison with a similar hybrid approach proposed in the literature demonstrates how our approach significantly reduce prediction errors especially when few experiments on the real system are performed.},
	pages = {3123--3140},
	number = {12},
	journaltitle = {The Computer Journal},
	author = {Ataie, Ehsan and Evangelinou, Athanasia and Gianniti, Eugenio and Ardagna, Danilo},
	urldate = {2024-03-07},
	date = {2022-12-30},
	langid = {english},
	file = {Ataie et al. - 2022 - A Hybrid Machine Learning Approach for Performance Modeling of Cloud-Based Big Data Applications.pdf:C\:\\Users\\Alex\\Zotero\\storage\\6FW7NAXT\\Ataie et al. - 2022 - A Hybrid Machine Learning Approach for Performance Modeling of Cloud-Based Big Data Applications.pdf:application/pdf},
}

@collection{grandinetti_high-performance_2019,
	location = {Cham},
	title = {High-Performance Computing and Big Data Analysis: Second International Congress, {TopHPC} 2019, Tehran, Iran, April 23–25, 2019, Revised Selected Papers},
	volume = {891},
	isbn = {978-3-030-33494-9 978-3-030-33495-6},
	url = {http://link.springer.com/10.1007/978-3-030-33495-6},
	series = {Communications in Computer and Information Science},
	shorttitle = {High-Performance Computing and Big Data Analysis},
	publisher = {Springer International Publishing},
	editor = {Grandinetti, Lucio and Mirtaheri, Seyedeh Leili and Shahbazian, Reza},
	urldate = {2024-03-11},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-33495-6},
	file = {Grandinetti et al. - 2019 - High-Performance Computing and Big Data Analysis Second International Congress, TopHPC 2019, Tehran.pdf:C\:\\Users\\Alex\\Zotero\\storage\\QVCQP9Q4\\978-3-030-33495-6.pdf:application/pdf},
}

@inproceedings{ataie_combined_2016,
	location = {Timisoara, Romania},
	title = {A Combined Analytical Modeling Machine Learning Approach for Performance Prediction of {MapReduce} Jobs in Cloud Environment},
	isbn = {978-1-5090-5707-8},
	url = {http://ieeexplore.ieee.org/document/7829644/},
	doi = {10.1109/SYNASC.2016.072},
	abstract = {Nowadays {MapReduce} and its open source implementation, Apache Hadoop, are the most widespread solutions for handling massive dataset on clusters of commodity hardware. At the expense of a somewhat reduced performance in comparison to {HPC} technologies, the {MapReduce} framework provides fault tolerance and automatic parallelization without any efforts by developers. Since in many cases Hadoop is adopted to support business critical activities, it is often important to predict with fair conﬁdence the execution time of submitted jobs, for instance when {SLAs} are established with end-users. In this work, we propose and validate a hybrid approach exploiting both queuing networks and support vector regression, in order to achieve a good accuracy without too many costly experiments on a real setup. The experimental results show how the proposed approach attains a 21\% improvement in accuracy over applying machine learning techniques without any support from analytical models.},
	eventtitle = {2016 18th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing ({SYNASC})},
	pages = {431--439},
	booktitle = {2016 18th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing ({SYNASC})},
	publisher = {{IEEE}},
	author = {Ataie, Ehsan and Gianniti, Eugenio and Ardagna, Danilo and Movaghar, Ali},
	urldate = {2024-03-11},
	date = {2016-09},
	langid = {english},
	file = {Ataie et al. - 2016 - A Combined Analytical Modeling Machine Learning Approach for Performance Prediction of MapReduce Job.pdf:C\:\\Users\\Alex\\Zotero\\storage\\IZGZ7ISB\\Ataie et al. - 2016 - A Combined Analytical Modeling Machine Learning Approach for Performance Prediction of MapReduce Job.pdf:application/pdf},
}

@misc{rizzi_support_2016,
	title = {Support vector regression model for {BigData} systems},
	url = {http://arxiv.org/abs/1612.01458},
	abstract = {Nowadays Big Data are becoming more and more important. Many sectors of our economy are now guided by data-driven decision processes. Big Data and business intelligence applications are facilitated by the {MapReduce} programming model while, at infrastructural layer, cloud computing provides ﬂexible and cost eﬀective solutions for allocating on demand large clusters. In such systems, capacity allocation, which is the ability to optimally size minimal resources for achieve a certain level of performance, is a key challenge to enhance performance for {MapReduce} jobs and minimize cloud resource costs. In order to do so, one of the biggest challenge is to build an accurate performance model to estimate job execution time of {MapReduce} systems. Previous works applied simulation based models for modeling such systems. Although this approach can accurately describe the behavior of Big Data clusters, it is too computationally expensive and does not scale to large system. We try to overcome these issues by applying machine learning techniques. More precisely we focus on Support Vector Regression ({SVR}) which is intrinsically more robust w.r.t other techniques, like, e.g., neural networks, and less sensitive to outliers in the training set. To better investigate these beneﬁts, we compare {SVR} to linear regression.},
	number = {{arXiv}:1612.01458},
	publisher = {{arXiv}},
	author = {Rizzi, Alessandro Maria},
	urldate = {2024-03-11},
	date = {2016-12-05},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1612.01458 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Computer Science - Performance},
	file = {Rizzi - 2016 - Support vector regression model for BigData systems.pdf:C\:\\Users\\Alex\\Zotero\\storage\\8AX25J33\\Rizzi - 2016 - Support vector regression model for BigData systems.pdf:application/pdf},
}

@article{ahmed_enhanced_2021,
	title = {An Enhanced Parallelisation Model for Performance Prediction of Apache Spark on a Multinode Hadoop Cluster},
	volume = {5},
	issn = {2504-2289},
	url = {https://www.mdpi.com/2504-2289/5/4/65},
	doi = {10.3390/bdcc5040065},
	abstract = {Big data frameworks play a vital role in storing, processing, and analysing large datasets. Apache Spark has been established as one of the most popular big data engines for its efﬁciency and reliability. However, one of the signiﬁcant problems of the Spark system is performance prediction. Spark has more than 150 conﬁgurable parameters, and conﬁguration of so many parameters is challenging task when determining the suitable parameters for the system. In this paper, we proposed two distinct parallelisation models for performance prediction. Our insight is that each node in a Hadoop cluster can communicate with identical nodes, and a certain function of the non-parallelisable runtime can be estimated accordingly. Both models use simple equations that allows us to predict the runtime when the size of the job and the number of executables are known. The proposed models were evaluated based on ﬁve {HiBench} workloads, Kmeans, {PageRank}, Graph ({NWeight}), {SVM}, and {WordCount}. The workload’s empirical data were ﬁtted with one of the two models meeting the accuracy requirements. Finally, the experimental ﬁndings show that the model can be a handy and helpful tool for scheduling and planning system deployment.},
	pages = {65},
	number = {4},
	journaltitle = {Big Data and Cognitive Computing},
	shortjournal = {{BDCC}},
	author = {Ahmed, Nasim and Barczak, Andre L. C. and Rashid, Mohammad A. and Susnjak, Teo},
	urldate = {2024-03-11},
	date = {2021-11-05},
	langid = {english},
	file = {Ahmed et al. - 2021 - An Enhanced Parallelisation Model for Performance Prediction of Apache Spark on a Multinode Hadoop C.pdf:C\:\\Users\\Alex\\Zotero\\storage\\H5264IGW\\Ahmed et al. - 2021 - An Enhanced Parallelisation Model for Performance Prediction of Apache Spark on a Multinode Hadoop C.pdf:application/pdf},
}

@article{liu_estimation_2016,
	title = {Estimation Accuracy on Execution Time of Run-Time Tasks in a Heterogeneous Distributed Environment},
	volume = {16},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/16/9/1386},
	doi = {10.3390/s16091386},
	abstract = {Distributed Computing has achieved tremendous development since cloud computing was proposed in 2006, and played a vital role promoting rapid growth of data collecting and analysis models, e.g., Internet of things, Cyber-Physical Systems, Big Data Analytics, etc. Hadoop has become a data convergence platform for sensor networks. As one of the core components, {MapReduce} facilitates allocating, processing and mining of collected large-scale data, where speculative execution strategies help solve straggler problems. However, there is still no efﬁcient solution for accurate estimation on execution time of run-time tasks, which can affect task allocation and distribution in {MapReduce}. In this paper, task execution data have been collected and employed for the estimation. A two-phase regression ({TPR}) method is proposed to predict the ﬁnishing time of each task accurately. Detailed data of each task have drawn interests with detailed analysis report being made. According to the results, the prediction accuracy of concurrent tasks’ execution time can be improved, in particular for some regular jobs.},
	pages = {1386},
	number = {9},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Liu, Qi and Cai, Weidong and Jin, Dandan and Shen, Jian and Fu, Zhangjie and Liu, Xiaodong and Linge, Nigel},
	urldate = {2024-03-11},
	date = {2016-08-30},
	langid = {english},
	file = {Liu et al. - 2016 - Estimation Accuracy on Execution Time of Run-Time Tasks in a Heterogeneous Distributed Environment.pdf:C\:\\Users\\Alex\\Zotero\\storage\\KK3Y2R2T\\Liu et al. - 2016 - Estimation Accuracy on Execution Time of Run-Time Tasks in a Heterogeneous Distributed Environment.pdf:application/pdf},
}

@inproceedings{amannejad_fast_2019,
	location = {Milan, Italy},
	title = {Fast and Lightweight Execution Time Predictions for Spark Applications},
	isbn = {978-1-72812-705-7},
	url = {https://ieeexplore.ieee.org/document/8814547/},
	doi = {10.1109/CLOUD.2019.00088},
	abstract = {Users and operators of cloud-based Spark clusters often require quick insights on how the execution time of an application is likely to be impacted by the resources allocated to the application, e.g., the number of Spark executor cores assigned, and the size of the data to be processed. Existing techniques typically require extensive prior executions of the application under various resource allocation settings and data sizes to obtain an accurate model. In this paper, we explore the accuracy of a model with less prior executions of the application. Such a model can be useful for situations where quick predictions are required and little cluster resources are available for building a model. We use logs from two executions of an application with small sample data and different resource settings and explore the accuracy of the predictions for other resource allocation settings and input data sizes.},
	eventtitle = {2019 {IEEE} 12th International Conference on Cloud Computing ({CLOUD})},
	pages = {493--495},
	booktitle = {2019 {IEEE} 12th International Conference on Cloud Computing ({CLOUD})},
	publisher = {{IEEE}},
	author = {Amannejad, Yasaman and Shah, Sarah and Krishnamurthy, Diwakar and Wang, Mea},
	urldate = {2024-03-12},
	date = {2019-07},
	langid = {english},
	file = {Amannejad et al. - 2019 - Fast and Lightweight Execution Time Predictions for Spark Applications.pdf:C\:\\Users\\Alex\\Zotero\\storage\\SC4IZLUX\\Amannejad et al. - 2019 - Fast and Lightweight Execution Time Predictions for Spark Applications.pdf:application/pdf},
}

@article{alipourfard_cherrypick_nodate,
	title = {{CherryPick}: Adaptively Unearthing the Best Cloud Conﬁgurations for Big Data Analytics},
	abstract = {Picking the right cloud conﬁguration for recurring big data analytics jobs running in clouds is hard, because there can be tens of possible {VM} instance types and even more cluster sizes to pick from. Choosing poorly can signiﬁcantly degrade performance and increase the cost to run a job by 2-3x on average, and as much as 12x in the worst-case. However, it is challenging to automatically identify the best conﬁguration for a broad spectrum of applications and cloud conﬁgurations with low search cost. {CherryPick} is a system that leverages Bayesian Optimization to build performance models for various applications, and the models are just accurate enough to distinguish the best or close-to-the-best conﬁguration from the rest with only a few test runs. Our experiments on ﬁve analytic applications in {AWS} {EC}2 show that {CherryPick} has a 45-90\% chance to ﬁnd optimal conﬁgurations, otherwise near-optimal, saving up to 75\% search cost compared to existing solutions.},
	author = {Alipourfard, Omid and Liu, Hongqiang Harry and Chen, Jianshu and Venkataraman, Shivaram and Yu, Minlan and Zhang, Ming},
	langid = {english},
	file = {Alipourfard et al. - CherryPick Adaptively Unearthing the Best Cloud Conﬁgurations for Big Data Analytics.pdf:C\:\\Users\\Alex\\Zotero\\storage\\XDAZEP8J\\Alipourfard et al. - CherryPick Adaptively Unearthing the Best Cloud Conﬁgurations for Big Data Analytics.pdf:application/pdf},
}

@article{delimitrou_quasar_nodate,
	title = {Quasar: Resource-Efﬁcient and {QoS}-Aware Cluster Management},
	abstract = {Cloud computing promises ﬂexibility and high performance for users and high cost-efﬁciency for operators. Nevertheless, most cloud facilities operate at very low utilization, hurting both cost effectiveness and future scalability.},
	author = {Delimitrou, Christina and Kozyrakis, Christos},
	langid = {english},
	file = {Delimitrou und Kozyrakis - Quasar Resource-Efﬁcient and QoS-Aware Cluster Management.pdf:C\:\\Users\\Alex\\Zotero\\storage\\5FCHU37P\\Delimitrou und Kozyrakis - Quasar Resource-Efﬁcient and QoS-Aware Cluster Management.pdf:application/pdf},
}

@inproceedings{verbitskiy_cobell_2018,
	location = {Nicosia},
	title = {{CoBell}: Runtime Prediction for Distributed Dataflow Jobs in Shared Clusters},
	isbn = {978-1-5386-7899-2},
	url = {https://ieeexplore.ieee.org/document/8590998/},
	doi = {10.1109/CloudCom2018.2018.00029},
	shorttitle = {{CoBell}},
	abstract = {Distributed dataﬂow systems have been developed to help users analyze and process large datasets. While they make it easier for users to develop massively-parallel programs, users still have to choose the amount of resources for the execution of their jobs. Yet, users do not necessarily understand workload and system dynamics, while they often have constraints like runtime targets and budgets. Addressing this problem, systems have been developed that automatically select the required amount of resources to fulﬁll the users’ constraints. However, interference with co-located workloads can introduce a signiﬁcant variance into the runtimes of jobs and make accurate runtime prediction harder.},
	eventtitle = {2018 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	pages = {81--88},
	booktitle = {2018 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	publisher = {{IEEE}},
	author = {Verbitskiy, Ilya and Thamsen, Lauritz and Renner, Thomas and Kao, Odej},
	urldate = {2024-03-12},
	date = {2018-12},
	langid = {english},
	file = {Verbitskiy et al. - 2018 - CoBell Runtime Prediction for Distributed Dataflow Jobs in Shared Clusters.pdf:C\:\\Users\\Alex\\Zotero\\storage\\W85FARDS\\Verbitskiy et al. - 2018 - CoBell Runtime Prediction for Distributed Dataflow Jobs in Shared Clusters.pdf:application/pdf},
}

@inproceedings{ardagna_performance_2018,
	location = {Berlin Germany},
	title = {Performance Prediction of Cloud-Based Big Data Applications},
	isbn = {978-1-4503-5095-2},
	url = {https://dl.acm.org/doi/10.1145/3184407.3184420},
	doi = {10.1145/3184407.3184420},
	abstract = {Data heterogeneity and irregularity are key characteristics of big data applications that often overwhelm the existing software and hardware infrastructures. In such context, the flexibility and elasticity provided by the cloud computing paradigm offer a natural approach to cost-effectively adapting the allocated resources to the application’s current needs. Yet, the same characteristics impose extra challenges to predicting the performance of cloud-based big data applications, a central step in proper management and planning. This paper explores two modeling approaches for performance prediction of cloud-based big data applications. We evaluate a queuing-based analytical model and a novel fast ad-hoc simulator in various scenarios based on different applications and infrastructure setups. Our results show that our approaches can predict average application execution times with 26\% relative error in the very worst case and about 12\% on average. Moreover, our simulator provides performance estimates 70 times faster than state of the art simulation tools.},
	eventtitle = {{ICPE} '18: {ACM}/{SPEC} International Conference on Performance Engineering},
	pages = {192--199},
	booktitle = {Proceedings of the 2018 {ACM}/{SPEC} International Conference on Performance Engineering},
	publisher = {{ACM}},
	author = {Ardagna, Danilo and Barbierato, Enrico and Evangelinou, Athanasia and Gianniti, Eugenio and Gribaudo, Marco and Pinto, Túlio B. M. and Guimarães, Anna and Couto Da Silva, Ana Paula and Almeida, Jussara M.},
	urldate = {2024-03-12},
	date = {2018-03-30},
	langid = {english},
	file = {Ardagna et al. - 2018 - Performance Prediction of Cloud-Based Big Data Applications.pdf:C\:\\Users\\Alex\\Zotero\\storage\\5VBFHK7N\\Ardagna et al. - 2018 - Performance Prediction of Cloud-Based Big Data Applications.pdf:application/pdf},
}

@inproceedings{maros_machine_2019,
	location = {Milan, Italy},
	title = {Machine Learning for Performance Prediction of Spark Cloud Applications},
	isbn = {978-1-72812-705-7},
	url = {https://ieeexplore.ieee.org/document/8814514/},
	doi = {10.1109/CLOUD.2019.00028},
	abstract = {Big data applications and analytics are employed in many sectors for a variety of goals: improving customers satisfaction, predicting market behavior or improving processes in public health. These applications consist of complex software stacks that are often run on cloud systems. Predicting execution times is important for estimating the cost of cloud services and for effectively managing the underlying resources at runtime. Machine Learning ({ML}), providing black box solutions to model the relationship between application performance and system conﬁguration without requiring in-detail knowledge of the system, has become a popular way of predicting the performance of big data applications. We investigate the cost-beneﬁts of using supervised {ML} models for predicting the performance of applications on Spark, one of today’s most widely used frameworks for big data analysis. We compare our approach with Ernest (an {ML}-based technique proposed in the literature by the Spark inventors) on a range of scenarios, application workloads, and cloud system conﬁgurations. Our experiments show that Ernest can accurately estimate the performance of very regular applications, but it fails when applications exhibit more irregular patterns and/or when extrapolating on bigger data set sizes. Results show that our models match or exceed Ernest’s performance, sometimes enabling us to reduce the prediction error from 126-187\% to only 5-19\%.},
	eventtitle = {2019 {IEEE} 12th International Conference on Cloud Computing ({CLOUD})},
	pages = {99--106},
	booktitle = {2019 {IEEE} 12th International Conference on Cloud Computing ({CLOUD})},
	publisher = {{IEEE}},
	author = {Maros, Alexandre and Murai, Fabricio and Couto Da Silva, Ana Paula and M. Almeida, Jussara and Lattuada, Marco and Gianniti, Eugenio and Hosseini, Marjan and Ardagna, Danilo},
	urldate = {2024-03-12},
	date = {2019-07},
	langid = {english},
	file = {Maros et al. - 2019 - Machine Learning for Performance Prediction of Spark Cloud Applications.pdf:C\:\\Users\\Alex\\Zotero\\storage\\5C2QJUI5\\Maros et al. - 2019 - Machine Learning for Performance Prediction of Spark Cloud Applications.pdf:application/pdf},
}

@inproceedings{gulino_performance_2020,
	location = {Nice, France},
	title = {Performance Prediction for Data-driven Workflows on Apache Spark},
	isbn = {978-1-72819-238-3},
	url = {https://ieeexplore.ieee.org/document/9285944/},
	doi = {10.1109/MASCOTS50786.2020.9285944},
	abstract = {Spark is an in-memory framework for implementing distributed applications of various types. Predicting the execution time of Spark applications is an important but challenging problem that has been tackled in the past few years by several studies; most of them achieving good prediction accuracy on simple applications (e.g. known {ML} algorithms or {SQL}-based applications). In this work, we consider complex data-driven workﬂow applications, in which the execution and data ﬂow can be modeled by Directly Acyclic Graphs ({DAGs}). Workﬂows can be made of an arbitrary combination of known tasks, each applying a set of Spark operations to their input data. By adopting a hybrid approach, combining analytical and machine learning ({ML}) models, trained on small {DAGs}, we can predict, with good accuracy, the execution time of unseen workﬂows of higher complexity and size.},
	eventtitle = {2020 28th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems ({MASCOTS})},
	pages = {1--8},
	booktitle = {2020 28th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems ({MASCOTS})},
	publisher = {{IEEE}},
	author = {Gulino, Andrea and Canakoglu, Arif and Ceri, Stefano and Ardagna, Danilo},
	urldate = {2024-03-12},
	date = {2020-11-17},
	langid = {english},
	file = {Gulino et al. - 2020 - Performance Prediction for Data-driven Workflows on Apache Spark.pdf:C\:\\Users\\Alex\\Zotero\\storage\\AUF4TVAY\\Gulino et al. - 2020 - Performance Prediction for Data-driven Workflows on Apache Spark.pdf:application/pdf},
}
